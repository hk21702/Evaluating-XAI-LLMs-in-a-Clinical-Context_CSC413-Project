{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Faithfulness on our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import shap\n",
    "import shap\n",
    "from transformers import Pipeline\n",
    "\n",
    "import os \n",
    "import numpy\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "data_dir = \"output/\"\n",
    "destination_dir = \"./\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_short_path = \"data/test_10_top50_short.csv\"\n",
    "labels_10_top50 = pd.read_csv('data/icd10_codes_top50.csv')\n",
    "code_labels_10 = pd.read_csv(\"data/icd10_codes.csv\")\n",
    "print(\"dataset loaded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "MAX_POSITION_EMBEDDINGS = 512\n",
    "MODEL = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "CKPT = os.path.join(data_dir,\"best_model_state.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes\n",
      "bert model and tokenizer initialized\n"
     ]
    }
   ],
   "source": [
    "# Create class dictionaries\n",
    "classes = [class_ for class_ in code_labels_10[\"icd_code\"] if class_]\n",
    "class2id = {class_: id for id, class_ in enumerate(classes)}\n",
    "id2class = {id: class_ for class_, id in class2id.items()}\n",
    "\n",
    "print(\"classes\")\n",
    "\n",
    "config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(classes),\n",
    "    id2label=id2class,\n",
    "    label2id=class2id,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    return_unused_kwargs=True,\n",
    ")\n",
    "\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(MODEL)\n",
    "model_bert = AutoModel.from_pretrained(MODEL, config=config, cache_dir='./model_ckpt/')\n",
    "print(\"bert model and tokenizer initialized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n"
     ]
    }
   ],
   "source": [
    "class TokenizerWrapper:\n",
    "    def __init__(self, tokenizer, length, classes):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = length\n",
    "        self.classes = classes\n",
    "        self.class2id = {class_: id for id, class_ in enumerate(self.classes)}\n",
    "        self.id2class = {id: class_ for class_, id in self.class2id.items()}\n",
    "        \n",
    "    def multi_labels_to_ids(self, labels: list[str]) -> list[float]:\n",
    "        ids = [0.0] * len(self.class2id)  # BCELoss requires float as target type\n",
    "        for label in labels:\n",
    "            ids[self.class2id[label]] = 1.0\n",
    "        return ids\n",
    "    \n",
    "    def tokenize_function(self, example):\n",
    "        result = self.tokenizer(\n",
    "            example[\"text\"],\n",
    "            max_length = self.max_length,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        result[\"label\"] = torch.tensor([self.multi_labels_to_ids(eval(label)) for label in example[\"label\"]])\n",
    "        return result\n",
    "        \n",
    "data_files = {\n",
    "        \"test\": test_short_path,\n",
    "    }\n",
    "\n",
    "tokenizer_wrapper = TokenizerWrapper(tokenizer_bert, MAX_POSITION_EMBEDDINGS, classes)\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "dataset = dataset.map(tokenizer_wrapper.tokenize_function, batched=True, num_proc=1)\n",
    "dataset = dataset.with_format(\"torch\")\n",
    "print(\"dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.bert_model = model_bert\n",
    "        self.can_generate = model_bert.can_generate\n",
    "        self.base_model_prefix = model_bert.base_model_prefix\n",
    "        self.get_input_embeddings = model_bert.get_input_embeddings\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear = torch.nn.Linear(self.bert_model.config.hidden_size, 50)\n",
    "    \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "    \n",
    "model_bert = BERTClass()\n",
    "model_bert.load_state_dict(torch.load(CKPT))\n",
    "model_bert = model_bert.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_ICD10_Pipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        return self.tokenizer(\n",
    "            text,\n",
    "            max_length = MAX_POSITION_EMBEDDINGS,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        ids = model_inputs['input_ids'].to(self.device, dtype = torch.long)\n",
    "        mask = model_inputs['attention_mask'].to(self.device, dtype = torch.long)\n",
    "        token_type_ids = model_inputs['token_type_ids'].to(self.device, dtype = torch.long)\n",
    "        outputs = self.model(ids, mask, token_type_ids).to(self.device)\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        probs = F.sigmoid(model_outputs).detach().cpu().numpy() # if there's more than one possible diagnosis\n",
    "\n",
    "        output = []\n",
    "        for i, prob in enumerate(probs[0]):\n",
    "            label = self.model.config.id2label[i]\n",
    "            score = prob\n",
    "            output.append({\"label\": label, \"score\": score})\n",
    "        # print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code for faithfulness calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = BERT_ICD10_Pipeline(model=model_bert, tokenizer=tokenizer_bert, device = device)\n",
    "print(\"pipeline initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.sample(shap_input, 2)\n",
    "# shap_values = explainer(\n",
    "#         shap_input,\n",
    "#         batch_size=5,\n",
    "#         outputs=shap.Explanation.argsort.flip[:2]\n",
    "#         )\n",
    "# print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_arrays_shap(inputs, pred_func, model, tokenizer, top_k = 5):\n",
    "    \"\"\" Function to create the arrays corresponding to the shap \n",
    "    \n",
    "    The output is in the format [[input_index_0, input_index_0, ... input_index_n, input_index_n], \n",
    "    [rationale_token_index_0 (for input 0), rationale_token_index_1 (for input 0), ... rationale_token_index_k-1 (for input n), rationale_token_index_k (for input n)]]. \n",
    "    This is used as an indexing array for masking.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # get the shap values over the inputs\n",
    "    shap_values = explainer(inputs, batch_size=5)\n",
    "    \n",
    "    # get the mode inferences for the inputs\n",
    "    inferences = pred_func(inputs, model, tokenizer)\n",
    "    indices_array = None\n",
    "    # get the longest \n",
    "    \n",
    "    for i, val in enumerate(shap_values):\n",
    "        # get the choosen labels\n",
    "        print(\"Inferences: \", inferences)\n",
    "        choosen_labels = np.where(inferences[i] > 0.5)\n",
    "        choosen_labels = np.unique(choosen_labels)\n",
    "        \n",
    "        # convert the indices to labels\n",
    "        choosen_labels = np.array(choosen_labels).astype(int)\n",
    "        print(\"Choosen label: \", choosen_labels)\n",
    "        choosen_labels = [id2class[label] for label in choosen_labels]\n",
    "        print(id2class)\n",
    "        print(choosen_labels)\n",
    "        \n",
    "        # for each shap value, index in via it's choosen labels\n",
    "        total_top_k_indices = np.array([])\n",
    "        top_val = min(top_k, len(choosen_labels))\n",
    "        print(top_val)\n",
    "        print(choosen_labels)\n",
    "        \n",
    "        \n",
    "        for label in choosen_labels:\n",
    "            # get the top k shap value indices\n",
    "            print(label)\n",
    "            top_k_indices = np.argsort(shap_values[i, :, label].values)[-top_val:]\n",
    "            print(top_k_indices)\n",
    "            total_top_k_indices = np.append(total_top_k_indices, top_k_indices)\n",
    "        \n",
    "        # sort the indices array to be in ascending order\n",
    "        total_top_k_indices = np.sort(total_top_k_indices)\n",
    "        # remove duplicates\n",
    "        total_top_k_indices = np.unique(total_top_k_indices)\n",
    "        # this might be wrong, it seems like shap returns indices outside of the token range\n",
    "        # so I'm not sure if shap is using the same tokenization function as ours.\n",
    "        total_top_k_indices = total_top_k_indices[total_top_k_indices < 2048]\n",
    "        \n",
    "        # create a array of the same shape of total_top_k_indices and fill with value i\n",
    "        index_array = np.full(total_top_k_indices.shape, i)\n",
    "        \n",
    "        if i == 0:\n",
    "            indices_array = [index_array.tolist(), total_top_k_indices.tolist()]\n",
    "        else:\n",
    "            # append index array to indices array[0]\n",
    "            indices_array[0] = indices_array[0] + index_array.tolist()\n",
    "            # append total_top_k_indices to indices array[1]\n",
    "            indices_array[1] = indices_array[1] + total_top_k_indices.tolist()\n",
    "    \n",
    "    return np.array(indices_array).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_model_token(texts, model, tokenizer_bert):\n",
    "    # print(len(texts))\n",
    "    # tk = tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS).to(device)\n",
    "    # print(type(tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS)))\n",
    "    # print(\"token_att: \", dir(tk))\n",
    "    tk = tokenizer_bert(\n",
    "            texts,\n",
    "            max_length = MAX_POSITION_EMBEDDINGS,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "    ids = tk['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = tk['attention_mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = tk['token_type_ids'].to(device, dtype = torch.long)\n",
    "    outputs = model_bert(ids, mask, token_type_ids)\n",
    "    # tensor_logits = outputs[0]\n",
    "    # probas = tensor_logits.sigmoid().detach().cpu().numpy()\n",
    "    probas = F.sigmoid(outputs).detach().cpu().numpy()\n",
    "    return probas\n",
    "\n",
    "def predictor_model_no_token(texts, model, tokenizer_bert):\n",
    "    # print(len(texts))\n",
    "    # tk = tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS).to(device)\n",
    "    # tokenization is removed but still need to set texts to device\n",
    "    # i'm not sure why this is a list and don't have time to debug\n",
    "    # print(\"Texts_type:\", type(texts))\n",
    "    # print(\"Texts_dir:\",  dir(texts))\n",
    "    # texts.to(device)\n",
    "    # outputs = model(**texts)\n",
    "    # tensor_logits = outputs[0]\n",
    "    # probas = tensor_logits.sigmoid().detach().cpu().numpy()\n",
    "    ids = texts['input_ids'].to(device, dtype = torch.long)\n",
    "    mask = texts['attention_mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = texts['token_type_ids'].to(device, dtype = torch.long)\n",
    "    outputs = model_bert(ids, mask, token_type_ids)\n",
    "    tensor_logits = outputs\n",
    "    probas = tensor_logits.sigmoid().detach().cpu().numpy()\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11849\n",
      "shap computed\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23772/2374230797.py\", line 22, in <module>\n",
      "    indices_array = get_index_arrays_shap(test_data, predictor_model_token, model_bert, tokenizer_bert)\n",
      "  File \"/tmp/ipykernel_23772/666571880.py\", line 11, in get_index_arrays_shap\n",
      "    shap_values = explainer(inputs, batch_size=5)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 128, in __call__\n",
      "    return super().__call__(\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/explainers/_explainer.py\", line 266, in __call__\n",
      "    row_result = self.explain_row(\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 174, in explain_row\n",
      "    self.owen(fm, self._curr_base_value, f11, max_evals - 2, outputs, fixed_context, batch_size, silent)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/explainers/_partition.py\", line 284, in owen\n",
      "    fout = fm(batch_masks)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py\", line 70, in __call__\n",
      "    return self._full_masking_call(masks, batch_size=batch_size)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/utils/_masked_model.py\", line 147, in _full_masking_call\n",
      "    outputs = self.model(*joined_masked_inputs)\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/shap/models/_transformers_pipeline.py\", line 30, in __call__\n",
      "    pipeline_dicts = self.inner_model(list(strings))\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/h/u15/c9/00/lokejuan/Documents/CSC413-Project/venv/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:46, 46.55s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306]\n",
      "indices_array: [[  0]\n",
      " [306]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,     1,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.55186784e-01 2.05997363e-01 2.90016085e-01 8.43228325e-02\n",
      "  1.41649535e-02 2.37522367e-03 6.54014796e-02 2.07230393e-02\n",
      "  1.31806091e-03 3.72008719e-02 4.75009112e-03 1.57904439e-02\n",
      "  6.69004545e-02 3.20143625e-02 6.98765367e-03 2.47657150e-02\n",
      "  7.92803802e-03 2.57777683e-02 1.02302870e-02 1.53036304e-02\n",
      "  2.34964248e-02 1.72638297e-02 6.65080920e-02 9.03374515e-03\n",
      "  1.41099896e-02 3.57989979e-04 4.06943401e-03 1.41209587e-02\n",
      "  5.26387990e-03 2.06101816e-02 2.63856035e-02 7.76365807e-04\n",
      "  4.99163941e-03 8.08831584e-03 1.64563756e-03 5.17118862e-03\n",
      "  2.85614305e-03 2.16149376e-03 2.71515604e-02 3.26861115e-03\n",
      "  4.35119873e-04 3.72159702e-04 1.16518037e-02 1.18317772e-02\n",
      "  1.37441570e-03 7.03345090e-02 3.77750732e-02 5.54602081e-03\n",
      "  4.68719844e-03 1.44807401e-03]]\n",
      "[[9.6239376e-01 2.1710026e-01 2.9923677e-01 8.8340431e-02 3.0947112e-02\n",
      "  4.2160084e-03 6.5427817e-02 3.0840492e-02 3.3013034e-03 3.4800898e-02\n",
      "  5.0975326e-03 1.5125600e-02 8.8751413e-02 5.7700299e-02 1.2388626e-02\n",
      "  3.4392118e-02 1.3988556e-02 2.8528579e-02 1.0336139e-02 2.1130098e-02\n",
      "  1.4586656e-02 3.1922285e-02 6.2085800e-02 8.2880035e-03 1.0472643e-02\n",
      "  5.3335901e-04 3.6346018e-03 2.5567258e-02 6.3955830e-03 3.5239846e-02\n",
      "  3.8670059e-02 5.9012382e-04 7.1248082e-03 8.4590027e-03 2.6983169e-03\n",
      "  8.8353371e-03 2.4430242e-03 1.5081442e-03 3.1475022e-02 3.3638745e-03\n",
      "  5.2379369e-04 5.9271423e-04 1.9531669e-02 1.2332307e-02 2.6150716e-03\n",
      "  3.5859596e-02 4.8134640e-02 6.5936935e-03 8.8234982e-03 2.6739899e-03]]\n",
      "[[9.55186784e-01 2.05997363e-01 2.90016085e-01 8.43228325e-02\n",
      "  1.41649535e-02 2.37522367e-03 6.54014796e-02 2.07230393e-02\n",
      "  1.31806091e-03 3.72008719e-02 4.75009112e-03 1.57904439e-02\n",
      "  6.69004545e-02 3.20143625e-02 6.98765367e-03 2.47657150e-02\n",
      "  7.92803802e-03 2.57777683e-02 1.02302870e-02 1.53036304e-02\n",
      "  2.34964248e-02 1.72638297e-02 6.65080920e-02 9.03374515e-03\n",
      "  1.41099896e-02 3.57989979e-04 4.06943401e-03 1.41209587e-02\n",
      "  5.26387990e-03 2.06101816e-02 2.63856035e-02 7.76365807e-04\n",
      "  4.99163941e-03 8.08831584e-03 1.64563756e-03 5.17118862e-03\n",
      "  2.85614305e-03 2.16149376e-03 2.71515604e-02 3.26861115e-03\n",
      "  4.35119873e-04 3.72159702e-04 1.16518037e-02 1.18317772e-02\n",
      "  1.37441570e-03 7.03345090e-02 3.77750732e-02 5.54602081e-03\n",
      "  4.68719844e-03 1.44807401e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.06118178\n",
      "Comprehensiveness for iteration:  0.93799514\n",
      "Sufficency for iteration:  0.065226115\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.93799514\n",
      "Comprehensiveness q1 (25% percentile):  0.9379951357841492\n",
      "Comprehensiveness q3 (75% percentile):  0.9379951357841492\n",
      "\n",
      "\n",
      "Sufficency Median:  0.065226115\n",
      "Sufficency q1 (25% percentile):  0.06522611528635025\n",
      "Sufficency q3 (75% percentile):  0.06522611528635025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faithfulness\n",
    "# this reimports the library for easy testing in the notebook\n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(faithfulness)\n",
    "\n",
    "MAX_LEN=512\n",
    "\n",
    "\n",
    "# tokenize the test dataset\n",
    "test_data =  dataset['test']['text'][:1]\n",
    "print(len(test_data))\n",
    "print(len(test_data[0]))\n",
    "\n",
    "masker = shap.maskers.Text(pipeline.tokenizer)\n",
    "explainer = shap.Explainer(pipeline, masker)\n",
    "print(\"shap computed\")\n",
    "\n",
    "inputs = tokenizer_bert(test_data, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='pt')\n",
    "print(\"input type: \", type(inputs))\n",
    "\n",
    "indices_array = get_index_arrays_shap(test_data, predictor_model_token, model_bert, tokenizer_bert)\n",
    "print(\"indices_array:\", indices_array)\n",
    "\n",
    "inputs_rationale_removed = faithfulness.remove_rationale_words(inputs, indices_array, join=False, tokenized=True)\n",
    "inputs_other_removed = faithfulness.remove_other_words(inputs, indices_array, join=False, tokenized=True)\n",
    "\n",
    "# print(\"rational removed: \", inputs_rationale_removed)\n",
    "# print(\"other removed: \", inputs_other_removed)\n",
    "print(\"rational removed type: \", type(inputs_rationale_removed))\n",
    "print(\"other removed type: \", type(inputs_other_removed))\n",
    "\n",
    "ind, faith = faithfulness.calculate_faithfulness(inputs, [inputs_rationale_removed], [inputs_other_removed ], model_bert, tokenizer_bert, predictor_model_no_token, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "##################################################################################################################################\n",
    "# Returns the faithfulness results for choice of:\n",
    "# - input_data being the same dimension/characteristics as the test/val/train dataset used for our classifier of choice Bert or OPT.\n",
    "# - start_index being the starting point index of the input_data\n",
    "# - N being the size of input dataset (this is how many texts you want an explanation for)\n",
    "# - B being the size of explanation batch (this is how many texts your machine can explain at a given instance)\n",
    "# - k being the top k features defined as our rationales for explanation\n",
    "# Precondition: pipeline with tokenizer and model correctly initialized along with masker and explainer for SHAP\n",
    "######################################################################################################################################\n",
    "def get_faith_shap(input_data, start_index, N, B, k):\n",
    "    num_steps = math.ceil(N/B)\n",
    "    tail_n =  N % B    \n",
    "    overall_ind = []\n",
    "    overall_faith = []\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        print(i)\n",
    "        if i == (num_steps - 1): # on the final step\n",
    "            end_index = start_index + tail_n\n",
    "            input_subset = input_data[start_index:end_index]\n",
    "            start_index += tail_n\n",
    "            \n",
    "        else:\n",
    "            end_index = start_index + B\n",
    "            input_subset = input_data[start_index:end_index]\n",
    "            start_index += B\n",
    "    \n",
    "        inputs = tokenizer_bert(test_data, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        print(\"input type: \", type(inputs))\n",
    "    \n",
    "        indices_array = get_index_arrays_shap(test_data, predictor_model_token, model_bert, tokenizer_bert, k)\n",
    "        print(\"indices_array:\", indices_array)\n",
    "    \n",
    "        inputs_rationale_removed = faithfulness.remove_rationale_words(inputs, indices_array, join=False, tokenized=True)\n",
    "        inputs_other_removed = faithfulness.remove_other_words(inputs, indices_array, join=False, tokenized=True)\n",
    "    \n",
    "        # print(\"rational removed: \", inputs_rationale_removed)\n",
    "        # print(\"other removed: \", inputs_other_removed)\n",
    "        print(\"rational removed type: \", type(inputs_rationale_removed))\n",
    "        print(\"other removed type: \", type(inputs_other_removed))\n",
    "    \n",
    "        ind, faith = faithfulness.calculate_faithfulness(inputs, [inputs_rationale_removed], [inputs_other_removed ], model_bert, tokenizer_bert, predictor_model_no_token, tokenized=True)\n",
    "        overall_ind.append(ind)\n",
    "        overall_faith.extend(faith)\n",
    "        \n",
    "    return overall_ind, overall_faith, np.mean(overall_faith)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:43, 43.87s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[305]\n",
      "indices_array: [[  0]\n",
      " [305]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,     1,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7180080e-01 2.8015932e-01 2.0382515e-01 9.2902824e-02 4.3507133e-02\n",
      "  3.5159944e-03 7.2951838e-02 2.5297815e-02 2.2975130e-03 2.2455044e-02\n",
      "  4.2810882e-03 1.3725296e-02 8.4536456e-02 2.9051246e-02 1.4331803e-02\n",
      "  3.0473912e-02 8.1125554e-03 3.2583717e-02 9.9583827e-03 1.8459367e-02\n",
      "  2.2230998e-02 2.2016868e-02 9.1387093e-02 1.2234463e-02 9.5043192e-03\n",
      "  5.6080346e-04 3.2871282e-03 2.9381042e-02 5.6406814e-03 3.2628622e-02\n",
      "  2.6156098e-02 4.9620646e-04 1.1220735e-02 7.2549265e-03 2.6503480e-03\n",
      "  7.5741336e-03 2.6605241e-03 1.9004460e-03 3.9290864e-02 3.1544319e-03\n",
      "  4.1497190e-04 4.7471537e-04 1.5901078e-02 9.5083965e-03 2.8053040e-03\n",
      "  5.7168212e-02 2.8703986e-02 8.8433707e-03 5.9503587e-03 1.5705611e-03]]\n",
      "[[9.78843689e-01 1.92536026e-01 2.73086399e-01 8.94972160e-02\n",
      "  2.07661968e-02 2.19411054e-03 6.82809576e-02 2.48360820e-02\n",
      "  1.65345171e-03 4.20278348e-02 2.94295955e-03 8.21331982e-03\n",
      "  6.75466731e-02 2.16491371e-02 1.19616101e-02 2.50255726e-02\n",
      "  8.43936391e-03 2.75440831e-02 6.16733497e-03 1.84726100e-02\n",
      "  2.21251808e-02 1.36995837e-02 6.54870644e-02 8.00098013e-03\n",
      "  1.07243108e-02 3.16689519e-04 1.94742985e-03 2.34527290e-02\n",
      "  4.13809856e-03 3.78937311e-02 2.83858497e-02 6.89161127e-04\n",
      "  7.00701354e-03 4.90766158e-03 1.93185150e-03 6.12865388e-03\n",
      "  1.72250986e-03 1.72258285e-03 2.54742336e-02 3.10685881e-03\n",
      "  2.72243895e-04 2.91166478e-04 1.55526465e-02 9.45517048e-03\n",
      "  1.93814316e-03 4.33289595e-02 3.34656127e-02 4.38976567e-03\n",
      "  3.33534065e-03 2.21818825e-03]]\n",
      "[[9.7180080e-01 2.8015932e-01 2.0382515e-01 9.2902824e-02 4.3507133e-02\n",
      "  3.5159944e-03 7.2951838e-02 2.5297815e-02 2.2975130e-03 2.2455044e-02\n",
      "  4.2810882e-03 1.3725296e-02 8.4536456e-02 2.9051246e-02 1.4331803e-02\n",
      "  3.0473912e-02 8.1125554e-03 3.2583717e-02 9.9583827e-03 1.8459367e-02\n",
      "  2.2230998e-02 2.2016868e-02 9.1387093e-02 1.2234463e-02 9.5043192e-03\n",
      "  5.6080346e-04 3.2871282e-03 2.9381042e-02 5.6406814e-03 3.2628622e-02\n",
      "  2.6156098e-02 4.9620646e-04 1.1220735e-02 7.2549265e-03 2.6503480e-03\n",
      "  7.5741336e-03 2.6605241e-03 1.9004460e-03 3.9290864e-02 3.1544319e-03\n",
      "  4.1497190e-04 4.7471537e-04 1.5901078e-02 9.5083965e-03 2.8053040e-03\n",
      "  5.7168212e-02 2.8703986e-02 8.8433707e-03 5.9503587e-03 1.5705611e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1, 1120,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.12282419\n",
      "Comprehensiveness for iteration:  0.99614733\n",
      "Sufficency for iteration:  0.123299226\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.99614733\n",
      "Comprehensiveness q1 (25% percentile):  0.9961473345756531\n",
      "Comprehensiveness q3 (75% percentile):  0.9961473345756531\n",
      "\n",
      "\n",
      "Sufficency Median:  0.123299226\n",
      "Sufficency q1 (25% percentile):  0.12329922616481781\n",
      "Sufficency q3 (75% percentile):  0.12329922616481781\n",
      "\n",
      "1\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.39s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309]\n",
      "indices_array: [[  0]\n",
      " [309]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,     1,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7269362e-01 1.9803452e-01 3.1362250e-01 7.0263036e-02 4.0696993e-02\n",
      "  5.0495332e-03 7.0480362e-02 3.0230915e-02 3.6090156e-03 4.4367578e-02\n",
      "  3.6514197e-03 2.0428006e-02 1.6604409e-01 4.8150863e-02 1.5194971e-02\n",
      "  3.2506045e-02 9.7138239e-03 4.1016448e-02 8.0020735e-03 2.9380001e-02\n",
      "  2.3894802e-02 2.8536253e-02 5.5321746e-02 8.0873696e-03 1.4739093e-02\n",
      "  7.0635276e-04 4.8110788e-03 3.0116418e-02 4.5059901e-03 3.0342791e-02\n",
      "  3.4720585e-02 1.2920684e-03 1.2324346e-02 6.8152640e-03 2.9281334e-03\n",
      "  8.5512204e-03 1.6536091e-03 1.1270676e-03 3.4898851e-02 4.1347984e-03\n",
      "  6.0816051e-04 5.0154130e-04 2.5225554e-02 1.2036949e-02 3.2326938e-03\n",
      "  4.5673136e-02 2.7029376e-02 6.8386393e-03 4.6198489e-03 1.4623877e-03]]\n",
      "[[9.7351182e-01 1.5604103e-01 2.8340623e-01 7.0959710e-02 2.0166473e-02\n",
      "  4.2374521e-03 5.3260848e-02 2.5500506e-02 4.0288116e-03 3.5755862e-02\n",
      "  4.4894349e-03 2.0232877e-02 6.9808766e-02 3.6634564e-02 8.5879499e-03\n",
      "  3.6987845e-02 7.5434125e-03 2.6065949e-02 9.3866726e-03 1.6845798e-02\n",
      "  1.3219730e-02 2.2214560e-02 5.4824285e-02 6.2046549e-03 1.0391319e-02\n",
      "  4.2721358e-04 2.2970822e-03 2.1035401e-02 7.3225945e-03 3.1400282e-02\n",
      "  5.1283143e-02 4.5557204e-04 7.9297191e-03 5.2833310e-03 2.1314016e-03\n",
      "  7.1752579e-03 2.4091697e-03 1.9773555e-03 3.3968110e-02 2.8050893e-03\n",
      "  6.7238935e-04 4.4401831e-04 1.8317278e-02 1.4817275e-02 2.8527903e-03\n",
      "  4.1131556e-02 1.7077873e-02 8.4166182e-03 4.6645603e-03 1.5570245e-03]]\n",
      "[[9.7269362e-01 1.9803452e-01 3.1362250e-01 7.0263036e-02 4.0696993e-02\n",
      "  5.0495332e-03 7.0480362e-02 3.0230915e-02 3.6090156e-03 4.4367578e-02\n",
      "  3.6514197e-03 2.0428006e-02 1.6604409e-01 4.8150863e-02 1.5194971e-02\n",
      "  3.2506045e-02 9.7138239e-03 4.1016448e-02 8.0020735e-03 2.9380001e-02\n",
      "  2.3894802e-02 2.8536253e-02 5.5321746e-02 8.0873696e-03 1.4739093e-02\n",
      "  7.0635276e-04 4.8110788e-03 3.0116418e-02 4.5059901e-03 3.0342791e-02\n",
      "  3.4720585e-02 1.2920684e-03 1.2324346e-02 6.8152640e-03 2.9281334e-03\n",
      "  8.5512204e-03 1.6536091e-03 1.1270676e-03 3.4898851e-02 4.1347984e-03\n",
      "  6.0816051e-04 5.0154130e-04 2.5225554e-02 1.2036949e-02 3.2326938e-03\n",
      "  4.5673136e-02 2.7029376e-02 6.8386393e-03 4.6198489e-03 1.4623877e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1, 1118,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.117213875\n",
      "Comprehensiveness for iteration:  0.9873275\n",
      "Sufficency for iteration:  0.11871833\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9873275\n",
      "Comprehensiveness q1 (25% percentile):  0.987327516078949\n",
      "Comprehensiveness q3 (75% percentile):  0.987327516078949\n",
      "\n",
      "\n",
      "Sufficency Median:  0.11871833\n",
      "Sufficency q1 (25% percentile):  0.11871833354234695\n",
      "Sufficency q3 (75% percentile):  0.11871833354234695\n",
      "\n",
      "2\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.58s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310]\n",
      "indices_array: [[  0]\n",
      " [310]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "             1,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.62603033e-01 2.50920057e-01 2.86624998e-01 6.79050833e-02\n",
      "  2.09788084e-02 2.52751540e-03 7.31572509e-02 2.17918679e-02\n",
      "  3.09203682e-03 1.96513887e-02 2.74766516e-03 1.54075725e-02\n",
      "  8.52394551e-02 3.81346643e-02 1.55610098e-02 2.81013101e-02\n",
      "  6.88060932e-03 3.21491584e-02 6.23272965e-03 1.66125949e-02\n",
      "  3.90898250e-02 2.45382190e-02 8.37696940e-02 8.59814510e-03\n",
      "  1.47531154e-02 4.43572470e-04 3.88359278e-03 1.48568852e-02\n",
      "  4.96950420e-03 3.69931534e-02 3.10263522e-02 5.83654968e-04\n",
      "  7.70316646e-03 5.66621823e-03 2.40924652e-03 7.07974611e-03\n",
      "  1.72076910e-03 1.71566207e-03 4.10500728e-02 4.32170788e-03\n",
      "  3.46474349e-04 5.13187202e-04 1.93340350e-02 8.43815040e-03\n",
      "  3.21304332e-03 5.68233170e-02 3.42333838e-02 1.03901969e-02\n",
      "  4.58307844e-03 2.08816607e-03]]\n",
      "[[9.7417939e-01 2.0240635e-01 2.6763982e-01 8.9638330e-02 3.0519478e-02\n",
      "  3.6368645e-03 7.0980787e-02 2.4370598e-02 2.6897911e-03 2.2537546e-02\n",
      "  4.9524065e-03 1.7741252e-02 9.0037368e-02 3.6905263e-02 1.5939910e-02\n",
      "  3.3178627e-02 1.2733344e-02 3.1207567e-02 9.7847497e-03 1.6920798e-02\n",
      "  3.3583801e-02 1.7823070e-02 1.0431620e-01 6.9617121e-03 9.4249919e-03\n",
      "  3.4148511e-04 3.8761785e-03 2.5383236e-02 7.2519048e-03 3.7748009e-02\n",
      "  4.1430797e-02 8.2619698e-04 1.0087867e-02 8.5635148e-03 3.3196846e-03\n",
      "  8.4184492e-03 2.5482178e-03 3.2758026e-03 3.4520678e-02 3.6680172e-03\n",
      "  3.5472334e-04 4.1397559e-04 1.6933104e-02 8.0352509e-03 3.7957232e-03\n",
      "  7.4835353e-02 3.7080050e-02 1.0583384e-02 4.8030489e-03 1.3727451e-03]]\n",
      "[[9.62603033e-01 2.50920057e-01 2.86624998e-01 6.79050833e-02\n",
      "  2.09788084e-02 2.52751540e-03 7.31572509e-02 2.17918679e-02\n",
      "  3.09203682e-03 1.96513887e-02 2.74766516e-03 1.54075725e-02\n",
      "  8.52394551e-02 3.81346643e-02 1.55610098e-02 2.81013101e-02\n",
      "  6.88060932e-03 3.21491584e-02 6.23272965e-03 1.66125949e-02\n",
      "  3.90898250e-02 2.45382190e-02 8.37696940e-02 8.59814510e-03\n",
      "  1.47531154e-02 4.43572470e-04 3.88359278e-03 1.48568852e-02\n",
      "  4.96950420e-03 3.69931534e-02 3.10263522e-02 5.83654968e-04\n",
      "  7.70316646e-03 5.66621823e-03 2.40924652e-03 7.07974611e-03\n",
      "  1.72076910e-03 1.71566207e-03 4.10500728e-02 4.32170788e-03\n",
      "  3.46474349e-04 5.13187202e-04 1.93340350e-02 8.43815040e-03\n",
      "  3.21304332e-03 5.68233170e-02 3.42333838e-02 1.03901969e-02\n",
      "  4.58307844e-03 2.08816607e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1, 173,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.064900264\n",
      "Comprehensiveness for iteration:  0.94697565\n",
      "Sufficency for iteration:  0.06853425\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.94697565\n",
      "Comprehensiveness q1 (25% percentile):  0.9469756484031677\n",
      "Comprehensiveness q3 (75% percentile):  0.9469756484031677\n",
      "\n",
      "\n",
      "Sufficency Median:  0.06853425\n",
      "Sufficency q1 (25% percentile):  0.0685342475771904\n",
      "Sufficency q3 (75% percentile):  0.0685342475771904\n",
      "\n",
      "3\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:45, 45.40s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[312]\n",
      "indices_array: [[  0]\n",
      " [312]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,     1,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6959597e-01 1.9363861e-01 2.0588310e-01 6.6292405e-02 2.1441776e-02\n",
      "  2.7346897e-03 5.1092431e-02 2.8241863e-02 2.4796417e-03 1.8957004e-02\n",
      "  3.0805964e-03 1.1708515e-02 1.5350635e-01 3.8587447e-02 1.0254528e-02\n",
      "  2.6257349e-02 6.3007036e-03 2.7509457e-02 1.4192399e-02 1.9681247e-02\n",
      "  2.8809300e-02 2.6465345e-02 5.5981725e-02 7.4469666e-03 1.0793010e-02\n",
      "  2.8497376e-04 2.6892766e-03 2.0341920e-02 5.0649219e-03 3.1623513e-02\n",
      "  2.6093194e-02 7.3982595e-04 7.0319432e-03 5.7991440e-03 3.0822426e-03\n",
      "  6.3738180e-03 1.4693995e-03 2.3711042e-03 2.9459748e-02 1.9292542e-03\n",
      "  5.6929112e-04 3.8903451e-04 1.5275567e-02 9.6272491e-03 4.1858419e-03\n",
      "  5.4390401e-02 3.1430993e-02 8.4945392e-03 7.0494846e-03 1.0935398e-03]]\n",
      "[[9.6403140e-01 1.5046471e-01 2.6154187e-01 5.8637071e-02 2.2097800e-02\n",
      "  2.8261971e-03 8.0813333e-02 1.8106239e-02 2.0724935e-03 1.8500485e-02\n",
      "  4.0366473e-03 6.2329336e-03 8.6686149e-02 2.7611120e-02 1.0707397e-02\n",
      "  2.9278886e-02 6.2995236e-03 2.0023288e-02 5.9264610e-03 1.0754702e-02\n",
      "  2.3562431e-02 1.4418836e-02 4.0232539e-02 7.6850248e-03 8.0210520e-03\n",
      "  3.6628929e-04 3.7898170e-03 1.4612731e-02 3.8605162e-03 2.8760932e-02\n",
      "  2.4711557e-02 5.3507398e-04 5.6460937e-03 7.0194160e-03 1.4602448e-03\n",
      "  5.2680187e-03 1.4415523e-03 1.2891017e-03 2.6688049e-02 1.4649902e-03\n",
      "  3.4310282e-04 1.9932180e-04 1.5312917e-02 8.3445888e-03 1.8274036e-03\n",
      "  4.0754721e-02 3.7423346e-02 4.3915086e-03 2.6111642e-03 1.1020241e-03]]\n",
      "[[9.6959597e-01 1.9363861e-01 2.0588310e-01 6.6292405e-02 2.1441776e-02\n",
      "  2.7346897e-03 5.1092431e-02 2.8241863e-02 2.4796417e-03 1.8957004e-02\n",
      "  3.0805964e-03 1.1708515e-02 1.5350635e-01 3.8587447e-02 1.0254528e-02\n",
      "  2.6257349e-02 6.3007036e-03 2.7509457e-02 1.4192399e-02 1.9681247e-02\n",
      "  2.8809300e-02 2.6465345e-02 5.5981725e-02 7.4469666e-03 1.0793010e-02\n",
      "  2.8497376e-04 2.6892766e-03 2.0341920e-02 5.0649219e-03 3.1623513e-02\n",
      "  2.6093194e-02 7.3982595e-04 7.0319432e-03 5.7991440e-03 3.0822426e-03\n",
      "  6.3738180e-03 1.4693995e-03 2.3711042e-03 2.9459748e-02 1.9292542e-03\n",
      "  5.6929112e-04 3.8903451e-04 1.5275567e-02 9.6272491e-03 4.1858419e-03\n",
      "  5.4390401e-02 3.1430993e-02 8.4945392e-03 7.0494846e-03 1.0935398e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1, 119,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.11008728\n",
      "Comprehensiveness for iteration:  1.0210749\n",
      "Sufficency for iteration:  0.107815094\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0210749\n",
      "Comprehensiveness q1 (25% percentile):  1.021074891090393\n",
      "Comprehensiveness q3 (75% percentile):  1.021074891090393\n",
      "\n",
      "\n",
      "Sufficency Median:  0.107815094\n",
      "Sufficency q1 (25% percentile):  0.10781509429216385\n",
      "Sufficency q3 (75% percentile):  0.10781509429216385\n",
      "\n",
      "4\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.51s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310]\n",
      "indices_array: [[  0]\n",
      " [310]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "             1,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7043008e-01 1.3669309e-01 3.1204665e-01 6.1510548e-02 2.3476347e-02\n",
      "  5.9903273e-03 5.8042187e-02 3.0892486e-02 3.3282356e-03 1.7207647e-02\n",
      "  5.3355647e-03 9.6402019e-03 7.5213507e-02 4.4499677e-02 1.3820169e-02\n",
      "  2.9260725e-02 8.8524446e-03 3.7721515e-02 7.8939414e-03 1.8850625e-02\n",
      "  2.7584901e-02 1.9839877e-02 6.3114837e-02 7.6316320e-03 1.2383785e-02\n",
      "  3.7331576e-04 3.9853444e-03 2.1513496e-02 5.4721306e-03 3.7667185e-02\n",
      "  2.6216215e-02 1.1912624e-03 7.7699488e-03 7.1169664e-03 3.7975302e-03\n",
      "  7.7372920e-03 1.9482464e-03 1.9290239e-03 3.3558786e-02 3.8347016e-03\n",
      "  7.6992880e-04 5.6593906e-04 1.9646011e-02 8.6560361e-03 3.4905591e-03\n",
      "  4.8566274e-02 4.2492248e-02 9.9886851e-03 5.9994026e-03 1.6288320e-03]]\n",
      "[[9.7934270e-01 2.1393935e-01 2.5511318e-01 7.8325577e-02 1.9249124e-02\n",
      "  3.5857144e-03 3.9647918e-02 2.4490634e-02 2.3958816e-03 2.9408129e-02\n",
      "  5.7217469e-03 1.3688370e-02 1.1357193e-01 3.0626088e-02 7.1237623e-03\n",
      "  3.4655247e-02 9.9298479e-03 3.5762202e-02 9.1388449e-03 1.9466024e-02\n",
      "  4.0536791e-02 1.3619465e-02 4.8631646e-02 7.5138593e-03 1.3500238e-02\n",
      "  4.6780243e-04 5.4809377e-03 1.7055605e-02 5.1388820e-03 3.4930754e-02\n",
      "  3.3429354e-02 6.7384844e-04 9.5094424e-03 5.2523199e-03 3.7124152e-03\n",
      "  5.3538168e-03 2.6085577e-03 1.8090870e-03 2.6160520e-02 2.4013538e-03\n",
      "  4.9363816e-04 2.8422702e-04 1.6259801e-02 7.5608287e-03 4.1468679e-03\n",
      "  4.9017958e-02 3.9475441e-02 7.9129562e-03 4.6281451e-03 2.0600951e-03]]\n",
      "[[9.7043008e-01 1.3669309e-01 3.1204665e-01 6.1510548e-02 2.3476347e-02\n",
      "  5.9903273e-03 5.8042187e-02 3.0892486e-02 3.3282356e-03 1.7207647e-02\n",
      "  5.3355647e-03 9.6402019e-03 7.5213507e-02 4.4499677e-02 1.3820169e-02\n",
      "  2.9260725e-02 8.8524446e-03 3.7721515e-02 7.8939414e-03 1.8850625e-02\n",
      "  2.7584901e-02 1.9839877e-02 6.3114837e-02 7.6316320e-03 1.2383785e-02\n",
      "  3.7331576e-04 3.9853444e-03 2.1513496e-02 5.4721306e-03 3.7667185e-02\n",
      "  2.6216215e-02 1.1912624e-03 7.7699488e-03 7.1169664e-03 3.7975302e-03\n",
      "  7.7372920e-03 1.9482464e-03 1.9290239e-03 3.3558786e-02 3.8347016e-03\n",
      "  7.6992880e-04 5.6593906e-04 1.9646011e-02 8.6560361e-03 3.4905591e-03\n",
      "  4.8566274e-02 4.2492248e-02 9.9886851e-03 5.9994026e-03 1.6288320e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1, 173,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.10610219\n",
      "Comprehensiveness for iteration:  0.9496761\n",
      "Sufficency for iteration:  0.11172461\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9496761\n",
      "Comprehensiveness q1 (25% percentile):  0.9496760964393616\n",
      "Comprehensiveness q3 (75% percentile):  0.9496760964393616\n",
      "\n",
      "\n",
      "Sufficency Median:  0.11172461\n",
      "Sufficency q1 (25% percentile):  0.1117246076464653\n",
      "Sufficency q3 (75% percentile):  0.1117246076464653\n",
      "\n",
      "5\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.53s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310]\n",
      "indices_array: [[  0]\n",
      " [310]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "             1,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7031140e-01 3.2521895e-01 2.7080128e-01 6.6295505e-02 2.6383759e-02\n",
      "  1.7204529e-03 2.8418373e-02 1.4419811e-02 2.3693419e-03 2.1072522e-02\n",
      "  3.5009456e-03 1.1911171e-02 7.4924149e-02 2.9597795e-02 1.2293315e-02\n",
      "  3.1843614e-02 1.0515473e-02 2.1325737e-02 9.0222144e-03 1.1882897e-02\n",
      "  2.5335915e-02 2.4161648e-02 5.5687740e-02 9.3496162e-03 1.8592449e-02\n",
      "  5.7438505e-04 3.2320113e-03 2.0776041e-02 5.9631458e-03 3.0258134e-02\n",
      "  3.8145814e-02 9.6262112e-04 5.4562772e-03 7.1146553e-03 2.1465884e-03\n",
      "  4.1763559e-03 1.9169844e-03 2.9262353e-03 3.1064536e-02 3.9815628e-03\n",
      "  7.0377893e-04 4.0327932e-04 1.6833309e-02 1.0202249e-02 4.1893297e-03\n",
      "  5.9404302e-02 2.9761443e-02 5.3974790e-03 3.9904416e-03 1.5061708e-03]]\n",
      "[[9.7504878e-01 1.1761581e-01 2.7645814e-01 7.9920292e-02 2.1554995e-02\n",
      "  1.8847147e-03 6.8163618e-02 1.8443165e-02 2.0860983e-03 2.6320392e-02\n",
      "  3.2966796e-03 1.1418333e-02 1.3137859e-01 2.7757192e-02 1.0917662e-02\n",
      "  2.8634790e-02 7.2129560e-03 3.3494234e-02 6.0273623e-03 1.4245054e-02\n",
      "  2.5449166e-02 1.7190479e-02 5.3590436e-02 8.3014099e-03 8.3073527e-03\n",
      "  3.5257457e-04 2.7609696e-03 2.8497273e-02 6.0626171e-03 2.9048476e-02\n",
      "  2.9215412e-02 5.8234052e-04 6.5903272e-03 8.3429385e-03 2.6017409e-03\n",
      "  5.7653361e-03 1.8872882e-03 1.3498275e-03 3.8528223e-02 3.5766624e-03\n",
      "  4.3574788e-04 3.2868516e-04 2.3111291e-02 9.5999232e-03 3.4942231e-03\n",
      "  5.1702071e-02 4.1906931e-02 1.1186304e-02 4.6538995e-03 1.3481824e-03]]\n",
      "[[9.7031140e-01 3.2521895e-01 2.7080128e-01 6.6295505e-02 2.6383759e-02\n",
      "  1.7204529e-03 2.8418373e-02 1.4419811e-02 2.3693419e-03 2.1072522e-02\n",
      "  3.5009456e-03 1.1911171e-02 7.4924149e-02 2.9597795e-02 1.2293315e-02\n",
      "  3.1843614e-02 1.0515473e-02 2.1325737e-02 9.0222144e-03 1.1882897e-02\n",
      "  2.5335915e-02 2.4161648e-02 5.5687740e-02 9.3496162e-03 1.8592449e-02\n",
      "  5.7438505e-04 3.2320113e-03 2.0776041e-02 5.9631458e-03 3.0258134e-02\n",
      "  3.8145814e-02 9.6262112e-04 5.4562772e-03 7.1146553e-03 2.1465884e-03\n",
      "  4.1763559e-03 1.9169844e-03 2.9262353e-03 3.1064536e-02 3.9815628e-03\n",
      "  7.0377893e-04 4.0327932e-04 1.6833309e-02 1.0202249e-02 4.1893297e-03\n",
      "  5.9404302e-02 2.9761443e-02 5.3974790e-03 3.9904416e-03 1.5061708e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1, 173,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.21381745\n",
      "Comprehensiveness for iteration:  0.9658436\n",
      "Sufficency for iteration:  0.22137895\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9658436\n",
      "Comprehensiveness q1 (25% percentile):  0.9658436179161072\n",
      "Comprehensiveness q3 (75% percentile):  0.9658436179161072\n",
      "\n",
      "\n",
      "Sufficency Median:  0.22137895\n",
      "Sufficency q1 (25% percentile):  0.22137895226478577\n",
      "Sufficency q3 (75% percentile):  0.22137895226478577\n",
      "\n",
      "6\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.64s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306]\n",
      "indices_array: [[  0]\n",
      " [306]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,     1,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6992773e-01 1.6519713e-01 2.6929766e-01 9.7958207e-02 3.4274772e-02\n",
      "  3.0778488e-03 5.1523197e-02 2.0360012e-02 2.3309251e-03 2.4095358e-02\n",
      "  3.3815275e-03 2.0368349e-02 6.7283876e-02 3.0679949e-02 1.4406265e-02\n",
      "  3.0070113e-02 1.0696204e-02 3.1971745e-02 6.8627992e-03 1.8825017e-02\n",
      "  2.6740804e-02 1.7880840e-02 5.6768514e-02 8.6864699e-03 6.7069819e-03\n",
      "  7.2497630e-04 2.4262075e-03 1.8877449e-02 4.9409335e-03 1.7006882e-02\n",
      "  2.3023987e-02 6.3991826e-04 4.9596061e-03 8.7751020e-03 2.2299595e-03\n",
      "  7.8678019e-03 1.8512785e-03 1.1332122e-03 2.7670251e-02 2.9874709e-03\n",
      "  4.7595956e-04 4.6184528e-04 1.6066063e-02 6.2662703e-03 1.7198789e-03\n",
      "  3.7881155e-02 2.7456878e-02 5.1827333e-03 4.8070555e-03 1.1873081e-03]]\n",
      "[[9.50215399e-01 2.16072112e-01 2.09315091e-01 1.00362003e-01\n",
      "  2.77913716e-02 2.87418254e-03 6.03771769e-02 3.28615010e-02\n",
      "  2.19302205e-03 3.13452221e-02 6.32857718e-03 1.73639450e-02\n",
      "  1.22915626e-01 3.36707160e-02 1.47448350e-02 5.03751598e-02\n",
      "  1.01329274e-02 2.62614917e-02 1.25693213e-02 2.56453026e-02\n",
      "  3.68422419e-02 1.40324729e-02 4.64884378e-02 9.32445750e-03\n",
      "  1.40625900e-02 4.30840562e-04 3.07736895e-03 1.63203888e-02\n",
      "  6.43315399e-03 2.82110572e-02 2.45243143e-02 9.54001036e-04\n",
      "  9.75048169e-03 5.74639579e-03 3.17956973e-03 5.69552882e-03\n",
      "  2.51636491e-03 1.89910980e-03 2.84622572e-02 4.05851053e-03\n",
      "  5.53783029e-04 3.98802309e-04 1.70965884e-02 8.06058384e-03\n",
      "  2.99594086e-03 9.06652361e-02 4.04789634e-02 9.15064849e-03\n",
      "  4.87959478e-03 1.81596889e-03]]\n",
      "[[9.6992773e-01 1.6519713e-01 2.6929766e-01 9.7958207e-02 3.4274772e-02\n",
      "  3.0778488e-03 5.1523197e-02 2.0360012e-02 2.3309251e-03 2.4095358e-02\n",
      "  3.3815275e-03 2.0368349e-02 6.7283876e-02 3.0679949e-02 1.4406265e-02\n",
      "  3.0070113e-02 1.0696204e-02 3.1971745e-02 6.8627992e-03 1.8825017e-02\n",
      "  2.6740804e-02 1.7880840e-02 5.6768514e-02 8.6864699e-03 6.7069819e-03\n",
      "  7.2497630e-04 2.4262075e-03 1.8877449e-02 4.9409335e-03 1.7006882e-02\n",
      "  2.3023987e-02 6.3991826e-04 4.9596061e-03 8.7751020e-03 2.2299595e-03\n",
      "  7.8678019e-03 1.8512785e-03 1.1332122e-03 2.7670251e-02 2.9874709e-03\n",
      "  4.7595956e-04 4.6184528e-04 1.6066063e-02 6.2662703e-03 1.7198789e-03\n",
      "  3.7881155e-02 2.7456878e-02 5.1827333e-03 4.8070555e-03 1.1873081e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.103904635\n",
      "Comprehensiveness for iteration:  0.87851936\n",
      "Sufficency for iteration:  0.118272446\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.87851936\n",
      "Comprehensiveness q1 (25% percentile):  0.8785193562507629\n",
      "Comprehensiveness q3 (75% percentile):  0.8785193562507629\n",
      "\n",
      "\n",
      "Sufficency Median:  0.118272446\n",
      "Sufficency q1 (25% percentile):  0.11827244609594345\n",
      "Sufficency q3 (75% percentile):  0.11827244609594345\n",
      "\n",
      "7\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.46s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306]\n",
      "indices_array: [[  0]\n",
      " [306]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,     1,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7367442e-01 2.2915436e-01 2.6286358e-01 5.6536138e-02 3.1106841e-02\n",
      "  2.7745254e-03 4.0273298e-02 1.5792904e-02 1.6459994e-03 1.8676078e-02\n",
      "  3.2086021e-03 8.4468890e-03 7.5137921e-02 4.4993717e-02 1.4107610e-02\n",
      "  3.3758141e-02 8.0747567e-03 2.4813445e-02 8.7653436e-03 2.0763831e-02\n",
      "  1.8283209e-02 1.7099785e-02 6.2769018e-02 7.5113955e-03 6.1913379e-03\n",
      "  2.8763266e-04 3.7261578e-03 2.2811664e-02 4.1381791e-03 3.7160289e-02\n",
      "  2.6797429e-02 7.2017993e-04 1.0935435e-02 4.6926001e-03 2.1476082e-03\n",
      "  4.3742051e-03 2.2676424e-03 1.0911698e-03 3.5464182e-02 2.9878204e-03\n",
      "  4.1148448e-04 3.9639469e-04 1.1244693e-02 5.8671013e-03 2.2496886e-03\n",
      "  3.5235263e-02 2.9559040e-02 6.0490333e-03 3.6023960e-03 1.4904183e-03]]\n",
      "[[9.6229494e-01 1.7709230e-01 2.8478831e-01 8.1912883e-02 2.3955405e-02\n",
      "  2.4023661e-03 6.1090335e-02 2.2510817e-02 2.0964395e-03 2.8550956e-02\n",
      "  4.5593027e-03 1.0279560e-02 1.0698013e-01 3.8664032e-02 1.0805312e-02\n",
      "  2.8107373e-02 8.6365640e-03 2.8097307e-02 8.9160930e-03 1.4475403e-02\n",
      "  2.9561825e-02 2.2655195e-02 6.2573284e-02 1.0509714e-02 1.3699286e-02\n",
      "  3.4209527e-04 2.7699368e-03 2.8145695e-02 3.9691692e-03 2.9016022e-02\n",
      "  2.1791259e-02 4.7467620e-04 7.6637315e-03 5.9052859e-03 1.7971307e-03\n",
      "  6.1277999e-03 2.2288095e-03 2.0658956e-03 5.2489035e-02 2.5297862e-03\n",
      "  4.3567628e-04 3.4157318e-04 1.3684881e-02 7.7320915e-03 1.8978621e-03\n",
      "  4.9929880e-02 2.4252616e-02 8.5900603e-03 3.4943956e-03 1.3342922e-03]]\n",
      "[[9.7367442e-01 2.2915436e-01 2.6286358e-01 5.6536138e-02 3.1106841e-02\n",
      "  2.7745254e-03 4.0273298e-02 1.5792904e-02 1.6459994e-03 1.8676078e-02\n",
      "  3.2086021e-03 8.4468890e-03 7.5137921e-02 4.4993717e-02 1.4107610e-02\n",
      "  3.3758141e-02 8.0747567e-03 2.4813445e-02 8.7653436e-03 2.0763831e-02\n",
      "  1.8283209e-02 1.7099785e-02 6.2769018e-02 7.5113955e-03 6.1913379e-03\n",
      "  2.8763266e-04 3.7261578e-03 2.2811664e-02 4.1381791e-03 3.7160289e-02\n",
      "  2.6797429e-02 7.2017993e-04 1.0935435e-02 4.6926001e-03 2.1476082e-03\n",
      "  4.3742051e-03 2.2676424e-03 1.0911698e-03 3.5464182e-02 2.9878204e-03\n",
      "  4.1148448e-04 3.9639469e-04 1.1244693e-02 5.8671013e-03 2.2496886e-03\n",
      "  3.5235263e-02 2.9559040e-02 6.0490333e-03 3.6023960e-03 1.4904183e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.083802536\n",
      "Comprehensiveness for iteration:  1.0272189\n",
      "Sufficency for iteration:  0.081581965\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0272189\n",
      "Comprehensiveness q1 (25% percentile):  1.0272189378738403\n",
      "Comprehensiveness q3 (75% percentile):  1.0272189378738403\n",
      "\n",
      "\n",
      "Sufficency Median:  0.081581965\n",
      "Sufficency q1 (25% percentile):  0.0815819650888443\n",
      "Sufficency q3 (75% percentile):  0.0815819650888443\n",
      "\n",
      "8\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.38s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304]\n",
      "indices_array: [[  0]\n",
      " [304]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,     1,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.5969111e-01 1.7492341e-01 3.2097408e-01 4.7066689e-02 1.9764302e-02\n",
      "  3.8252252e-03 4.8917621e-02 2.8575465e-02 2.7277374e-03 2.6500149e-02\n",
      "  4.2930073e-03 9.5001096e-03 8.1907384e-02 4.8323955e-02 1.9814217e-02\n",
      "  3.7377819e-02 8.1090843e-03 2.9639171e-02 1.0825227e-02 1.4212020e-02\n",
      "  2.7873138e-02 2.9112516e-02 5.8942843e-02 8.9442926e-03 1.1749057e-02\n",
      "  5.2189420e-04 2.2985472e-03 1.4781116e-02 3.9253659e-03 1.9183088e-02\n",
      "  2.3884665e-02 7.0565735e-04 7.2843591e-03 6.3892137e-03 2.2280950e-03\n",
      "  3.7873245e-03 1.7315632e-03 2.2283969e-03 2.9339500e-02 4.0101619e-03\n",
      "  5.2913191e-04 4.3465180e-04 1.9482579e-02 1.3522223e-02 4.0681302e-03\n",
      "  4.9123872e-02 3.1781048e-02 7.4062068e-03 4.1232519e-03 1.9801324e-03]]\n",
      "[[9.6282512e-01 2.0626886e-01 3.3796838e-01 1.1738447e-01 1.6456055e-02\n",
      "  4.8656529e-03 5.2580457e-02 2.9407060e-02 3.0373731e-03 2.5982320e-02\n",
      "  4.4739367e-03 1.2048834e-02 9.1038130e-02 4.4991516e-02 1.8882941e-02\n",
      "  3.4426410e-02 8.3550084e-03 3.4356624e-02 9.5440699e-03 2.1547260e-02\n",
      "  2.5988119e-02 1.9999258e-02 8.3004691e-02 1.1554810e-02 1.5430303e-02\n",
      "  6.0010381e-04 4.7450871e-03 2.5499729e-02 6.6168346e-03 3.9603151e-02\n",
      "  4.4627819e-02 8.0794620e-04 9.7803753e-03 7.8916820e-03 2.6181815e-03\n",
      "  5.9443871e-03 2.5271645e-03 1.3858520e-03 4.1178156e-02 5.5754981e-03\n",
      "  8.2091009e-04 3.7029778e-04 1.3318453e-02 1.1401042e-02 2.5619990e-03\n",
      "  6.5130666e-02 4.3336924e-02 6.2287701e-03 7.0532146e-03 1.8634344e-03]]\n",
      "[[9.5969111e-01 1.7492341e-01 3.2097408e-01 4.7066689e-02 1.9764302e-02\n",
      "  3.8252252e-03 4.8917621e-02 2.8575465e-02 2.7277374e-03 2.6500149e-02\n",
      "  4.2930073e-03 9.5001096e-03 8.1907384e-02 4.8323955e-02 1.9814217e-02\n",
      "  3.7377819e-02 8.1090843e-03 2.9639171e-02 1.0825227e-02 1.4212020e-02\n",
      "  2.7873138e-02 2.9112516e-02 5.8942843e-02 8.9442926e-03 1.1749057e-02\n",
      "  5.2189420e-04 2.2985472e-03 1.4781116e-02 3.9253659e-03 1.9183088e-02\n",
      "  2.3884665e-02 7.0565735e-04 7.2843591e-03 6.3892137e-03 2.2280950e-03\n",
      "  3.7873245e-03 1.7315632e-03 2.2283969e-03 2.9339500e-02 4.0101619e-03\n",
      "  5.2913191e-04 4.3465180e-04 1.9482579e-02 1.3522223e-02 4.0681302e-03\n",
      "  4.9123872e-02 3.1781048e-02 7.4062068e-03 4.1232519e-03 1.9801324e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.09123538\n",
      "Comprehensiveness for iteration:  0.97793406\n",
      "Sufficency for iteration:  0.093293995\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.97793406\n",
      "Comprehensiveness q1 (25% percentile):  0.9779340624809265\n",
      "Comprehensiveness q3 (75% percentile):  0.9779340624809265\n",
      "\n",
      "\n",
      "Sufficency Median:  0.093293995\n",
      "Sufficency q1 (25% percentile):  0.09329399466514587\n",
      "Sufficency q3 (75% percentile):  0.09329399466514587\n",
      "\n",
      "9\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.62s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310]\n",
      "indices_array: [[  0]\n",
      " [310]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "             1,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6897840e-01 2.1096386e-01 2.9627988e-01 7.1062036e-02 3.0248124e-02\n",
      "  2.5581380e-03 3.8990181e-02 2.1403551e-02 3.7873588e-03 2.9785963e-02\n",
      "  5.9822835e-03 9.3745412e-03 1.0192508e-01 4.2996414e-02 1.5044634e-02\n",
      "  3.1952150e-02 7.0984475e-03 3.2166567e-02 1.4331257e-02 2.1578360e-02\n",
      "  3.8298011e-02 1.5941435e-02 5.2768942e-02 6.2322305e-03 1.3983421e-02\n",
      "  5.7944795e-04 2.7502375e-03 2.2219935e-02 4.6774494e-03 3.6724932e-02\n",
      "  2.4168799e-02 6.4882729e-04 5.5622370e-03 6.6068880e-03 3.3458215e-03\n",
      "  7.7024559e-03 1.5989321e-03 2.0361808e-03 2.2703150e-02 2.6096720e-03\n",
      "  3.5979220e-04 3.9259566e-04 1.9537065e-02 1.0144125e-02 2.8078908e-03\n",
      "  3.3517111e-02 3.4128714e-02 8.4218401e-03 5.0113969e-03 2.2005518e-03]]\n",
      "[[9.5485026e-01 3.0604056e-01 3.2358065e-01 6.7023270e-02 2.3474896e-02\n",
      "  3.1382919e-03 4.2334005e-02 2.2043239e-02 2.3321896e-03 2.8391350e-02\n",
      "  5.1504304e-03 1.3934657e-02 8.5762948e-02 3.0779986e-02 1.5199922e-02\n",
      "  4.0569331e-02 1.0265007e-02 4.0281758e-02 9.3138926e-03 2.3117073e-02\n",
      "  2.4578849e-02 3.4113143e-02 8.6034589e-02 8.4458943e-03 1.9625276e-02\n",
      "  7.3077588e-04 6.1776163e-03 1.4693863e-02 5.0308597e-03 2.8255492e-02\n",
      "  3.7451155e-02 8.3590625e-04 5.8134575e-03 6.6033895e-03 3.2603382e-03\n",
      "  8.2041901e-03 2.1911927e-03 2.6129035e-03 4.2674541e-02 2.3947845e-03\n",
      "  1.0294700e-03 5.2841520e-04 1.4741115e-02 1.2110547e-02 5.7855318e-03\n",
      "  7.4301429e-02 3.4758750e-02 9.4177881e-03 3.6457097e-03 2.1055478e-03]]\n",
      "[[9.6897840e-01 2.1096386e-01 2.9627988e-01 7.1062036e-02 3.0248124e-02\n",
      "  2.5581380e-03 3.8990181e-02 2.1403551e-02 3.7873588e-03 2.9785963e-02\n",
      "  5.9822835e-03 9.3745412e-03 1.0192508e-01 4.2996414e-02 1.5044634e-02\n",
      "  3.1952150e-02 7.0984475e-03 3.2166567e-02 1.4331257e-02 2.1578360e-02\n",
      "  3.8298011e-02 1.5941435e-02 5.2768942e-02 6.2322305e-03 1.3983421e-02\n",
      "  5.7944795e-04 2.7502375e-03 2.2219935e-02 4.6774494e-03 3.6724932e-02\n",
      "  2.4168799e-02 6.4882729e-04 5.5622370e-03 6.6068880e-03 3.3458215e-03\n",
      "  7.7024559e-03 1.5989321e-03 2.0361808e-03 2.2703150e-02 2.6096720e-03\n",
      "  3.5979220e-04 3.9259566e-04 1.9537065e-02 1.0144125e-02 2.8078908e-03\n",
      "  3.3517111e-02 3.4128714e-02 8.4218401e-03 5.0113969e-03 2.2005518e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1, 173,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.12878683\n",
      "Comprehensiveness for iteration:  1.060286\n",
      "Sufficency for iteration:  0.12146423\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.060286\n",
      "Comprehensiveness q1 (25% percentile):  1.060286045074463\n",
      "Comprehensiveness q3 (75% percentile):  1.060286045074463\n",
      "\n",
      "\n",
      "Sufficency Median:  0.12146423\n",
      "Sufficency q1 (25% percentile):  0.12146423012018204\n",
      "Sufficency q3 (75% percentile):  0.12146423012018204\n",
      "\n",
      "0\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:45, 45.15s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295]\n",
      "indices_array: [[  0]\n",
      " [295]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,     1,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.8003012e-01 2.4928541e-01 2.6415452e-01 9.6641071e-02 1.7854750e-02\n",
      "  2.7399710e-03 5.9726670e-02 2.2343002e-02 3.7391130e-03 2.4449015e-02\n",
      "  3.9061848e-03 1.2355596e-02 8.7834276e-02 3.0449817e-02 1.8336521e-02\n",
      "  3.6271263e-02 1.0455728e-02 2.3933724e-02 9.6383570e-03 1.7734323e-02\n",
      "  2.1838471e-02 1.8286968e-02 4.5853641e-02 1.1184853e-02 1.1818694e-02\n",
      "  7.2923151e-04 2.7408348e-03 3.5008252e-02 6.1267433e-03 1.6756296e-02\n",
      "  3.5195902e-02 5.7346327e-04 7.4142488e-03 6.1186301e-03 2.4603184e-03\n",
      "  6.5132673e-03 1.8744282e-03 1.8340059e-03 2.9615948e-02 2.8114188e-03\n",
      "  4.1620791e-04 3.3466343e-04 2.0007985e-02 1.3466147e-02 3.0212812e-03\n",
      "  5.3217303e-02 4.4547278e-02 8.4341662e-03 5.1312475e-03 1.4606897e-03]]\n",
      "[[9.70929980e-01 2.40154490e-01 3.27821195e-01 8.23412091e-02\n",
      "  2.69220024e-02 2.52104388e-03 7.24571645e-02 2.17310395e-02\n",
      "  2.17971625e-03 2.89001800e-02 3.60003323e-03 1.54594006e-02\n",
      "  1.16875798e-01 3.32458280e-02 1.92655735e-02 4.02049460e-02\n",
      "  1.68173984e-02 2.32145861e-02 6.70856982e-03 1.16271395e-02\n",
      "  2.87471786e-02 1.86862350e-02 8.74273330e-02 1.73862111e-02\n",
      "  1.42003270e-02 3.91512032e-04 2.23553856e-03 1.98307186e-02\n",
      "  6.31612400e-03 1.48837361e-02 2.79516205e-02 7.13686517e-04\n",
      "  1.03202304e-02 5.60332695e-03 2.02896236e-03 6.75682630e-03\n",
      "  2.09055212e-03 1.53659692e-03 3.16087157e-02 3.90857505e-03\n",
      "  9.28944501e-04 4.18408803e-04 2.30446011e-02 1.46622574e-02\n",
      "  3.79114761e-03 6.26903400e-02 3.94540466e-02 7.43286731e-03\n",
      "  4.20242921e-03 1.25499361e-03]]\n",
      "[[9.8003012e-01 2.4928541e-01 2.6415452e-01 9.6641071e-02 1.7854750e-02\n",
      "  2.7399710e-03 5.9726670e-02 2.2343002e-02 3.7391130e-03 2.4449015e-02\n",
      "  3.9061848e-03 1.2355596e-02 8.7834276e-02 3.0449817e-02 1.8336521e-02\n",
      "  3.6271263e-02 1.0455728e-02 2.3933724e-02 9.6383570e-03 1.7734323e-02\n",
      "  2.1838471e-02 1.8286968e-02 4.5853641e-02 1.1184853e-02 1.1818694e-02\n",
      "  7.2923151e-04 2.7408348e-03 3.5008252e-02 6.1267433e-03 1.6756296e-02\n",
      "  3.5195902e-02 5.7346327e-04 7.4142488e-03 6.1186301e-03 2.4603184e-03\n",
      "  6.5132673e-03 1.8744282e-03 1.8340059e-03 2.9615948e-02 2.8114188e-03\n",
      "  4.1620791e-04 3.3466343e-04 2.0007985e-02 1.3466147e-02 3.0212812e-03\n",
      "  5.3217303e-02 4.4547278e-02 8.4341662e-03 5.1312475e-03 1.4606897e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1, 185,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.09830999\n",
      "Comprehensiveness for iteration:  1.1056714\n",
      "Sufficency for iteration:  0.08891429\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.1056714\n",
      "Comprehensiveness q1 (25% percentile):  1.1056714057922363\n",
      "Comprehensiveness q3 (75% percentile):  1.1056714057922363\n",
      "\n",
      "\n",
      "Sufficency Median:  0.08891429\n",
      "Sufficency q1 (25% percentile):  0.08891429007053375\n",
      "Sufficency q3 (75% percentile):  0.08891429007053375\n",
      "\n",
      "1\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.39s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306]\n",
      "indices_array: [[  0]\n",
      " [306]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,     1,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.3252426e-01 2.0487849e-01 2.4111021e-01 9.4599567e-02 3.4406442e-02\n",
      "  2.8762179e-03 5.8695160e-02 1.9453645e-02 2.8594257e-03 2.8411519e-02\n",
      "  5.0219600e-03 1.0627228e-02 1.2011873e-01 3.2176305e-02 1.3225995e-02\n",
      "  4.4140477e-02 9.5198313e-03 2.2557506e-02 9.4533712e-03 1.5305305e-02\n",
      "  5.2826259e-02 2.2787416e-02 6.2286366e-02 6.6984678e-03 1.6611667e-02\n",
      "  5.4971490e-04 3.3752886e-03 3.0510746e-02 6.6852439e-03 2.4688458e-02\n",
      "  2.1023804e-02 7.1286166e-04 6.8017314e-03 9.8756682e-03 2.3589705e-03\n",
      "  6.7134807e-03 1.7468726e-03 1.3412187e-03 4.2052254e-02 3.2887768e-03\n",
      "  3.0844478e-04 4.4164510e-04 1.2363967e-02 1.0146022e-02 3.2113700e-03\n",
      "  4.7057960e-02 3.7521362e-02 4.7641201e-03 2.9127891e-03 1.2882082e-03]]\n",
      "[[9.7762281e-01 1.6557401e-01 2.4789417e-01 8.3101191e-02 3.4388579e-02\n",
      "  1.9296061e-03 6.2378220e-02 2.5255628e-02 2.5259629e-03 3.3685535e-02\n",
      "  4.6205618e-03 2.6383398e-02 1.1198195e-01 3.5361055e-02 1.3589926e-02\n",
      "  2.6237762e-02 1.2396534e-02 3.3114363e-02 1.5610546e-02 1.8593695e-02\n",
      "  4.4623584e-02 2.9754113e-02 1.4239959e-01 9.7919321e-03 1.4739253e-02\n",
      "  5.2757695e-04 4.8286743e-03 2.5542958e-02 7.3162578e-03 2.9923815e-02\n",
      "  4.6138387e-02 8.4765581e-04 1.0049456e-02 1.1443080e-02 3.3109337e-03\n",
      "  8.1551876e-03 2.0680714e-03 2.3964960e-03 2.8412744e-02 5.0229109e-03\n",
      "  5.6369766e-04 3.8532290e-04 2.9602554e-02 1.7188055e-02 3.4240882e-03\n",
      "  6.9706708e-02 2.8125102e-02 9.5254807e-03 4.5739491e-03 2.5259615e-03]]\n",
      "[[9.3252426e-01 2.0487849e-01 2.4111021e-01 9.4599567e-02 3.4406442e-02\n",
      "  2.8762179e-03 5.8695160e-02 1.9453645e-02 2.8594257e-03 2.8411519e-02\n",
      "  5.0219600e-03 1.0627228e-02 1.2011873e-01 3.2176305e-02 1.3225995e-02\n",
      "  4.4140477e-02 9.5198313e-03 2.2557506e-02 9.4533712e-03 1.5305305e-02\n",
      "  5.2826259e-02 2.2787416e-02 6.2286366e-02 6.6984678e-03 1.6611667e-02\n",
      "  5.4971490e-04 3.3752886e-03 3.0510746e-02 6.6852439e-03 2.4688458e-02\n",
      "  2.1023804e-02 7.1286166e-04 6.8017314e-03 9.8756682e-03 2.3589705e-03\n",
      "  6.7134807e-03 1.7468726e-03 1.3412187e-03 4.2052254e-02 3.2887768e-03\n",
      "  3.0844478e-04 4.4164510e-04 1.2363967e-02 1.0146022e-02 3.2113700e-03\n",
      "  4.7057960e-02 3.7521362e-02 4.7641201e-03 2.9127891e-03 1.2882082e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.10666947\n",
      "Comprehensiveness for iteration:  0.9333807\n",
      "Sufficency for iteration:  0.11428291\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9333807\n",
      "Comprehensiveness q1 (25% percentile):  0.9333807229995728\n",
      "Comprehensiveness q3 (75% percentile):  0.9333807229995728\n",
      "\n",
      "\n",
      "Sufficency Median:  0.11428291\n",
      "Sufficency q1 (25% percentile):  0.11428291350603104\n",
      "Sufficency q3 (75% percentile):  0.11428291350603104\n",
      "\n",
      "2\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.39s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308]\n",
      "indices_array: [[  0]\n",
      " [308]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,     1,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.76100564e-01 2.01546133e-01 2.56408483e-01 5.13657667e-02\n",
      "  4.13719714e-02 3.22132208e-03 5.74189872e-02 2.11607236e-02\n",
      "  1.79024867e-03 2.17111446e-02 3.56071349e-03 1.12564275e-02\n",
      "  9.24561173e-02 2.48504337e-02 1.33285895e-02 3.12886834e-02\n",
      "  1.12897344e-02 2.19221991e-02 8.32321402e-03 1.03782164e-02\n",
      "  3.38946506e-02 2.15072669e-02 5.48632406e-02 7.81537127e-03\n",
      "  1.54382596e-02 4.56728885e-04 2.54393718e-03 1.29427183e-02\n",
      "  5.65038156e-03 1.73278917e-02 1.56751741e-02 7.82171381e-04\n",
      "  4.88113519e-03 3.69257922e-03 2.15431070e-03 5.34769008e-03\n",
      "  1.54435856e-03 1.50100642e-03 2.69307308e-02 4.23822924e-03\n",
      "  3.34292272e-04 4.05082479e-04 1.48773063e-02 8.68363306e-03\n",
      "  2.69912044e-03 2.73895208e-02 3.59751172e-02 5.23798447e-03\n",
      "  3.17328586e-03 1.17218366e-03]]\n",
      "[[9.61061180e-01 1.95717543e-01 2.66262263e-01 5.33971190e-02\n",
      "  3.45136002e-02 5.80482371e-03 6.04792610e-02 3.10197137e-02\n",
      "  2.86821532e-03 3.51795480e-02 2.91644596e-03 1.32320579e-02\n",
      "  1.11032486e-01 3.28855589e-02 2.39082854e-02 3.03556379e-02\n",
      "  1.03408806e-02 2.36943755e-02 1.05890725e-02 1.70023628e-02\n",
      "  5.83953187e-02 1.82915460e-02 4.59157676e-02 1.00119030e-02\n",
      "  1.24955298e-02 5.89215313e-04 3.65022453e-03 2.04348136e-02\n",
      "  1.06943678e-02 4.33452800e-02 3.42746489e-02 1.31979561e-03\n",
      "  1.49334213e-02 1.01250680e-02 2.38925428e-03 8.39792658e-03\n",
      "  3.08443978e-03 1.76138675e-03 3.66789214e-02 4.82241856e-03\n",
      "  5.43858099e-04 5.59122011e-04 2.28757560e-02 1.35661121e-02\n",
      "  4.87675238e-03 6.34543598e-02 3.17952111e-02 1.03565780e-02\n",
      "  5.74212009e-03 2.14922335e-03]]\n",
      "[[9.76100564e-01 2.01546133e-01 2.56408483e-01 5.13657667e-02\n",
      "  4.13719714e-02 3.22132208e-03 5.74189872e-02 2.11607236e-02\n",
      "  1.79024867e-03 2.17111446e-02 3.56071349e-03 1.12564275e-02\n",
      "  9.24561173e-02 2.48504337e-02 1.33285895e-02 3.12886834e-02\n",
      "  1.12897344e-02 2.19221991e-02 8.32321402e-03 1.03782164e-02\n",
      "  3.38946506e-02 2.15072669e-02 5.48632406e-02 7.81537127e-03\n",
      "  1.54382596e-02 4.56728885e-04 2.54393718e-03 1.29427183e-02\n",
      "  5.65038156e-03 1.73278917e-02 1.56751741e-02 7.82171381e-04\n",
      "  4.88113519e-03 3.69257922e-03 2.15431070e-03 5.34769008e-03\n",
      "  1.54435856e-03 1.50100642e-03 2.69307308e-02 4.23822924e-03\n",
      "  3.34292272e-04 4.05082479e-04 1.48773063e-02 8.68363306e-03\n",
      "  2.69912044e-03 2.73895208e-02 3.59751172e-02 5.23798447e-03\n",
      "  3.17328586e-03 1.17218366e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         168,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.06897583\n",
      "Comprehensiveness for iteration:  0.99679995\n",
      "Sufficency for iteration:  0.06919727\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.99679995\n",
      "Comprehensiveness q1 (25% percentile):  0.9967999458312988\n",
      "Comprehensiveness q3 (75% percentile):  0.9967999458312988\n",
      "\n",
      "\n",
      "Sufficency Median:  0.06919727\n",
      "Sufficency q1 (25% percentile):  0.06919726729393005\n",
      "Sufficency q3 (75% percentile):  0.06919726729393005\n",
      "\n",
      "3\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.53s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[307]\n",
      "indices_array: [[  0]\n",
      " [307]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,     1,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6965569e-01 2.2695099e-01 2.7776411e-01 6.0337029e-02 1.8241433e-02\n",
      "  2.1991534e-03 6.1941650e-02 2.5679786e-02 2.9746888e-03 2.6103260e-02\n",
      "  2.9203547e-03 1.4397620e-02 1.8049099e-01 3.1205082e-02 9.6369153e-03\n",
      "  2.7873844e-02 6.1767912e-03 3.0267574e-02 5.3004515e-03 1.6096484e-02\n",
      "  3.1878892e-02 2.3252683e-02 4.6887025e-02 8.3430773e-03 1.3114247e-02\n",
      "  3.6892027e-04 3.2016614e-03 2.8932991e-02 4.2277654e-03 2.2782521e-02\n",
      "  3.2971296e-02 1.1357514e-03 9.0085818e-03 7.2776238e-03 2.5014502e-03\n",
      "  4.3130005e-03 1.9955984e-03 1.9758709e-03 3.0720580e-02 4.8715486e-03\n",
      "  4.2639094e-04 3.7450882e-04 1.4071272e-02 1.0432930e-02 2.3500232e-03\n",
      "  6.8841957e-02 4.1171681e-02 1.0306403e-02 5.2715857e-03 8.9079904e-04]]\n",
      "[[9.7464162e-01 1.7539205e-01 3.6894408e-01 6.8206608e-02 3.0887377e-02\n",
      "  1.9706113e-03 6.2399127e-02 2.3963969e-02 2.9954268e-03 2.2605872e-02\n",
      "  4.1225860e-03 2.2597525e-02 8.8212192e-02 2.8251104e-02 1.3652160e-02\n",
      "  2.6237173e-02 7.7672987e-03 2.9941887e-02 1.2034108e-02 2.0132070e-02\n",
      "  2.9621013e-02 2.3733366e-02 5.4754116e-02 7.6676020e-03 1.1012734e-02\n",
      "  4.8185457e-04 3.1384605e-03 2.2543218e-02 5.8042160e-03 2.4047146e-02\n",
      "  3.5840247e-02 7.7980553e-04 7.9104863e-03 6.7119454e-03 2.9744385e-03\n",
      "  7.4566971e-03 1.6506033e-03 2.8969694e-03 3.8013604e-02 4.8274533e-03\n",
      "  3.8910055e-04 4.5519133e-04 1.7560685e-02 7.7897222e-03 3.7569555e-03\n",
      "  6.0755752e-02 3.4490868e-02 9.1616679e-03 5.0895847e-03 2.0344744e-03]]\n",
      "[[9.6965569e-01 2.2695099e-01 2.7776411e-01 6.0337029e-02 1.8241433e-02\n",
      "  2.1991534e-03 6.1941650e-02 2.5679786e-02 2.9746888e-03 2.6103260e-02\n",
      "  2.9203547e-03 1.4397620e-02 1.8049099e-01 3.1205082e-02 9.6369153e-03\n",
      "  2.7873844e-02 6.1767912e-03 3.0267574e-02 5.3004515e-03 1.6096484e-02\n",
      "  3.1878892e-02 2.3252683e-02 4.6887025e-02 8.3430773e-03 1.3114247e-02\n",
      "  3.6892027e-04 3.2016614e-03 2.8932991e-02 4.2277654e-03 2.2782521e-02\n",
      "  3.2971296e-02 1.1357514e-03 9.0085818e-03 7.2776238e-03 2.5014502e-03\n",
      "  4.3130005e-03 1.9955984e-03 1.9758709e-03 3.0720580e-02 4.8715486e-03\n",
      "  4.2639094e-04 3.7450882e-04 1.4071272e-02 1.0432930e-02 2.3500232e-03\n",
      "  6.8841957e-02 4.1171681e-02 1.0306403e-02 5.2715857e-03 8.9079904e-04]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.14220554\n",
      "Comprehensiveness for iteration:  0.99968654\n",
      "Sufficency for iteration:  0.14225012\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.99968654\n",
      "Comprehensiveness q1 (25% percentile):  0.9996865391731262\n",
      "Comprehensiveness q3 (75% percentile):  0.9996865391731262\n",
      "\n",
      "\n",
      "Sufficency Median:  0.14225012\n",
      "Sufficency q1 (25% percentile):  0.14225012063980103\n",
      "Sufficency q3 (75% percentile):  0.14225012063980103\n",
      "\n",
      "4\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.50s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[301]\n",
      "indices_array: [[  0]\n",
      " [301]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,     1,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6124786e-01 2.1139170e-01 1.9987755e-01 5.9519604e-02 2.2163950e-02\n",
      "  3.7644801e-03 4.1261505e-02 1.9922685e-02 3.1956332e-03 1.6753813e-02\n",
      "  3.6591892e-03 1.1908350e-02 9.8823383e-02 2.4578612e-02 1.8275876e-02\n",
      "  3.1429701e-02 9.5255803e-03 3.2924052e-02 8.4503079e-03 1.5551719e-02\n",
      "  2.1739641e-02 1.5942529e-02 7.7862896e-02 6.2822057e-03 7.5128530e-03\n",
      "  3.2052278e-04 3.1603905e-03 2.5976414e-02 4.3414072e-03 3.6350083e-02\n",
      "  3.6231861e-02 5.9854158e-04 8.6423308e-03 6.3611497e-03 2.0892273e-03\n",
      "  5.3086788e-03 2.5451619e-03 1.7813449e-03 4.5178317e-02 3.1351384e-03\n",
      "  4.6125133e-04 4.0134674e-04 1.3179991e-02 8.4037296e-03 3.3086638e-03\n",
      "  5.3473614e-02 3.2764222e-02 7.3764976e-03 6.0074609e-03 1.8749617e-03]]\n",
      "[[9.3644208e-01 2.4689578e-01 3.0243883e-01 7.0634402e-02 1.6505202e-02\n",
      "  5.6075971e-03 5.0678231e-02 2.5109980e-02 4.8654960e-03 2.8798291e-02\n",
      "  4.7271485e-03 1.5626924e-02 9.5299527e-02 3.5273939e-02 1.5686980e-02\n",
      "  1.4236598e-02 8.6841546e-03 2.7906215e-02 6.2758150e-03 1.9803908e-02\n",
      "  3.2356039e-02 1.8872773e-02 5.1544715e-02 8.7880921e-03 8.5349279e-03\n",
      "  4.7860737e-04 2.5228541e-03 1.9590009e-02 5.6040757e-03 2.4079714e-02\n",
      "  2.5908755e-02 6.1046402e-04 7.1500428e-03 7.6382337e-03 1.5053750e-03\n",
      "  6.5565952e-03 2.4828103e-03 2.6620745e-03 3.6153141e-02 2.5035157e-03\n",
      "  6.6109857e-04 3.2223458e-04 1.4190512e-02 8.8409679e-03 3.4571702e-03\n",
      "  6.3876852e-02 2.5551826e-02 8.3435196e-03 3.2364617e-03 1.8538991e-03]]\n",
      "[[9.6124786e-01 2.1139170e-01 1.9987755e-01 5.9519604e-02 2.2163950e-02\n",
      "  3.7644801e-03 4.1261505e-02 1.9922685e-02 3.1956332e-03 1.6753813e-02\n",
      "  3.6591892e-03 1.1908350e-02 9.8823383e-02 2.4578612e-02 1.8275876e-02\n",
      "  3.1429701e-02 9.5255803e-03 3.2924052e-02 8.4503079e-03 1.5551719e-02\n",
      "  2.1739641e-02 1.5942529e-02 7.7862896e-02 6.2822057e-03 7.5128530e-03\n",
      "  3.2052278e-04 3.1603905e-03 2.5976414e-02 4.3414072e-03 3.6350083e-02\n",
      "  3.6231861e-02 5.9854158e-04 8.6423308e-03 6.3611497e-03 2.0892273e-03\n",
      "  5.3086788e-03 2.5451619e-03 1.7813449e-03 4.5178317e-02 3.1351384e-03\n",
      "  4.6125133e-04 4.0134674e-04 1.3179991e-02 8.4037296e-03 3.3086638e-03\n",
      "  5.3473614e-02 3.2764222e-02 7.3764976e-03 6.0074609e-03 1.8749617e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1, 2624,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.12074634\n",
      "Comprehensiveness for iteration:  0.99625176\n",
      "Sufficency for iteration:  0.12120063\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.99625176\n",
      "Comprehensiveness q1 (25% percentile):  0.9962517619132996\n",
      "Comprehensiveness q3 (75% percentile):  0.9962517619132996\n",
      "\n",
      "\n",
      "Sufficency Median:  0.12120063\n",
      "Sufficency q1 (25% percentile):  0.12120062857866287\n",
      "Sufficency q3 (75% percentile):  0.12120062857866287\n",
      "\n",
      "5\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.46s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[292]\n",
      "indices_array: [[  0]\n",
      " [292]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,     1,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.66007471e-01 2.34571993e-01 3.35159183e-01 7.80055001e-02\n",
      "  1.76627636e-02 1.89505308e-03 4.66769561e-02 1.67106185e-02\n",
      "  2.01570173e-03 2.49202065e-02 5.35928598e-03 1.36870695e-02\n",
      "  1.24167807e-01 3.25349569e-02 1.39023531e-02 2.81882882e-02\n",
      "  1.18174069e-02 2.60168351e-02 6.05536066e-03 1.73903108e-02\n",
      "  2.59166621e-02 1.69265643e-02 3.55049260e-02 1.38450479e-02\n",
      "  1.03770895e-02 3.39882565e-04 1.70710497e-03 2.07778700e-02\n",
      "  4.26949514e-03 2.77150851e-02 3.77609730e-02 8.56933708e-04\n",
      "  8.52071960e-03 7.48524489e-03 2.58887536e-03 4.55010589e-03\n",
      "  1.74794230e-03 1.98366167e-03 2.20531411e-02 4.20619640e-03\n",
      "  4.04253107e-04 3.38267768e-04 1.20653799e-02 7.69475894e-03\n",
      "  3.16878827e-03 6.22238703e-02 3.42931487e-02 7.79846590e-03\n",
      "  5.01652341e-03 1.26593257e-03]]\n",
      "[[9.7430408e-01 2.9064283e-01 2.5124320e-01 6.1128940e-02 2.5833508e-02\n",
      "  4.2960639e-03 3.8200393e-02 2.0822428e-02 3.1306052e-03 1.9408455e-02\n",
      "  4.1772863e-03 9.3733901e-03 8.9069150e-02 3.3088714e-02 1.1332405e-02\n",
      "  3.8189664e-02 9.7464584e-03 2.6271220e-02 6.4718151e-03 2.3691777e-02\n",
      "  2.3069289e-02 2.2002345e-02 8.6860627e-02 7.1021249e-03 1.0692516e-02\n",
      "  5.7922298e-04 3.4706099e-03 1.8679289e-02 5.0052996e-03 2.6730973e-02\n",
      "  3.2555934e-02 7.7056815e-04 7.8631137e-03 6.5137334e-03 1.7517119e-03\n",
      "  8.3582122e-03 3.5108295e-03 2.1266018e-03 3.8106855e-02 4.5970809e-03\n",
      "  5.8799621e-04 4.5547046e-04 2.0521112e-02 6.2791966e-03 3.1315282e-03\n",
      "  5.3869586e-02 3.4566026e-02 6.2957401e-03 5.3092730e-03 1.8425076e-03]]\n",
      "[[9.66007471e-01 2.34571993e-01 3.35159183e-01 7.80055001e-02\n",
      "  1.76627636e-02 1.89505308e-03 4.66769561e-02 1.67106185e-02\n",
      "  2.01570173e-03 2.49202065e-02 5.35928598e-03 1.36870695e-02\n",
      "  1.24167807e-01 3.25349569e-02 1.39023531e-02 2.81882882e-02\n",
      "  1.18174069e-02 2.60168351e-02 6.05536066e-03 1.73903108e-02\n",
      "  2.59166621e-02 1.69265643e-02 3.55049260e-02 1.38450479e-02\n",
      "  1.03770895e-02 3.39882565e-04 1.70710497e-03 2.07778700e-02\n",
      "  4.26949514e-03 2.77150851e-02 3.77609730e-02 8.56933708e-04\n",
      "  8.52071960e-03 7.48524489e-03 2.58887536e-03 4.55010589e-03\n",
      "  1.74794230e-03 1.98366167e-03 2.20531411e-02 4.20619640e-03\n",
      "  4.04253107e-04 3.38267768e-04 1.20653799e-02 7.69475894e-03\n",
      "  3.16878827e-03 6.22238703e-02 3.42931487e-02 7.79846590e-03\n",
      "  5.01652341e-03 1.26593257e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 118,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.122300334\n",
      "Comprehensiveness for iteration:  0.988346\n",
      "Sufficency for iteration:  0.12374243\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.988346\n",
      "Comprehensiveness q1 (25% percentile):  0.9883459806442261\n",
      "Comprehensiveness q3 (75% percentile):  0.9883459806442261\n",
      "\n",
      "\n",
      "Sufficency Median:  0.12374243\n",
      "Sufficency q1 (25% percentile):  0.12374243140220642\n",
      "Sufficency q3 (75% percentile):  0.12374243140220642\n",
      "\n",
      "6\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:45, 45.33s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304]\n",
      "indices_array: [[  0]\n",
      " [304]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,     1,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7088683e-01 2.0935735e-01 2.7483568e-01 7.1182959e-02 2.2246385e-02\n",
      "  3.7485163e-03 5.2503560e-02 2.7270462e-02 2.1639213e-03 2.2050001e-02\n",
      "  2.2395283e-03 7.3103663e-03 9.8815270e-02 2.5464248e-02 9.5260162e-03\n",
      "  5.2164648e-02 5.9129912e-03 2.1993717e-02 6.7522130e-03 2.3790209e-02\n",
      "  2.2883859e-02 1.9498954e-02 7.2527990e-02 8.9220405e-03 9.1128396e-03\n",
      "  3.4928625e-04 3.7930214e-03 2.5454281e-02 3.0604228e-03 2.3749650e-02\n",
      "  2.2055881e-02 6.8325526e-04 7.5807562e-03 4.2016036e-03 1.8830847e-03\n",
      "  3.4527588e-03 2.0047333e-03 1.5984076e-03 2.0541484e-02 3.1021067e-03\n",
      "  5.2465708e-04 3.1813601e-04 1.1434589e-02 6.5475623e-03 2.0849968e-03\n",
      "  4.9754374e-02 3.2276861e-02 5.7149688e-03 3.3757619e-03 1.2021180e-03]]\n",
      "[[9.49397206e-01 1.85779184e-01 2.05771387e-01 5.58228530e-02\n",
      "  3.40220928e-02 2.65503372e-03 7.14477599e-02 2.08979882e-02\n",
      "  2.47984799e-03 2.08471194e-02 3.36796464e-03 1.04905209e-02\n",
      "  8.65736008e-02 2.90359836e-02 9.55229625e-03 2.80243140e-02\n",
      "  6.24509621e-03 2.10348964e-02 1.25470003e-02 1.46579165e-02\n",
      "  2.70532072e-02 1.22326761e-02 5.26660383e-02 8.72805994e-03\n",
      "  1.32889478e-02 3.65051237e-04 2.64682132e-03 1.68577041e-02\n",
      "  3.16326693e-03 2.16315407e-02 1.95946544e-02 5.14453277e-04\n",
      "  7.96753354e-03 5.92047116e-03 1.52456132e-03 4.04885411e-03\n",
      "  1.80076156e-03 1.46365550e-03 3.43633480e-02 3.11508565e-03\n",
      "  3.63841798e-04 4.33481851e-04 1.73429660e-02 9.14588198e-03\n",
      "  2.02662521e-03 3.50433961e-02 2.58780140e-02 6.09992072e-03\n",
      "  2.96040135e-03 1.68367662e-03]]\n",
      "[[9.7088683e-01 2.0935735e-01 2.7483568e-01 7.1182959e-02 2.2246385e-02\n",
      "  3.7485163e-03 5.2503560e-02 2.7270462e-02 2.1639213e-03 2.2050001e-02\n",
      "  2.2395283e-03 7.3103663e-03 9.8815270e-02 2.5464248e-02 9.5260162e-03\n",
      "  5.2164648e-02 5.9129912e-03 2.1993717e-02 6.7522130e-03 2.3790209e-02\n",
      "  2.2883859e-02 1.9498954e-02 7.2527990e-02 8.9220405e-03 9.1128396e-03\n",
      "  3.4928625e-04 3.7930214e-03 2.5454281e-02 3.0604228e-03 2.3749650e-02\n",
      "  2.2055881e-02 6.8325526e-04 7.5807562e-03 4.2016036e-03 1.8830847e-03\n",
      "  3.4527588e-03 2.0047333e-03 1.5984076e-03 2.0541484e-02 3.1021067e-03\n",
      "  5.2465708e-04 3.1813601e-04 1.1434589e-02 6.5475623e-03 2.0849968e-03\n",
      "  4.9754374e-02 3.2276861e-02 5.7149688e-03 3.3757619e-03 1.2021180e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1, 168,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.0930727\n",
      "Comprehensiveness for iteration:  1.0094278\n",
      "Sufficency for iteration:  0.09220342\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0094278\n",
      "Comprehensiveness q1 (25% percentile):  1.009427785873413\n",
      "Comprehensiveness q3 (75% percentile):  1.009427785873413\n",
      "\n",
      "\n",
      "Sufficency Median:  0.09220342\n",
      "Sufficency q1 (25% percentile):  0.09220342338085175\n",
      "Sufficency q3 (75% percentile):  0.09220342338085175\n",
      "\n",
      "7\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc90f014954c4182b9df9ac2974f6cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.69s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290]\n",
      "indices_array: [[  0]\n",
      " [290]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "             1,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[5.01873910e-01 1.14890330e-01 3.30559790e-01 8.21894109e-02\n",
      "  5.99471703e-02 2.48797797e-03 9.53073129e-02 1.08115515e-02\n",
      "  5.49139641e-03 3.90008427e-02 8.64466745e-03 1.38524789e-02\n",
      "  8.38588178e-02 2.97735687e-02 2.39477437e-02 5.81785589e-02\n",
      "  8.29641055e-03 3.24234329e-02 1.64914001e-02 3.56902257e-02\n",
      "  4.52030562e-02 1.88833978e-02 4.93673123e-02 6.64725574e-03\n",
      "  5.85150253e-03 1.72208436e-03 6.96560601e-03 1.20401587e-02\n",
      "  6.42477162e-03 8.78448933e-02 2.31018867e-02 1.08815276e-03\n",
      "  1.40712196e-02 4.03552409e-03 5.35340793e-03 5.38403867e-03\n",
      "  4.34629014e-03 1.99783826e-03 2.95502748e-02 6.25629211e-03\n",
      "  5.00632334e-04 1.27647526e-03 1.84096247e-02 6.15595840e-03\n",
      "  2.06255214e-03 4.52212133e-02 3.13074552e-02 3.70879075e-03\n",
      "  2.47691525e-03 4.49681887e-03]]\n",
      "[[9.71763015e-01 2.21173167e-01 2.47230068e-01 9.44106206e-02\n",
      "  2.28513237e-02 3.69774760e-03 5.43339960e-02 1.55164553e-02\n",
      "  3.64698656e-03 2.90114433e-02 4.59539657e-03 8.10714625e-03\n",
      "  1.18670486e-01 4.12832722e-02 1.71259642e-02 2.69363169e-02\n",
      "  6.47652335e-03 1.62580777e-02 9.93367936e-03 1.87348295e-02\n",
      "  3.14581506e-02 2.03847531e-02 6.44407645e-02 8.83304048e-03\n",
      "  1.52873769e-02 4.39765776e-04 4.04633023e-03 2.19460577e-02\n",
      "  4.70315525e-03 2.87811328e-02 3.11933067e-02 9.25196626e-04\n",
      "  6.73726341e-03 6.01768866e-03 2.25557550e-03 6.72358787e-03\n",
      "  1.23504899e-03 2.33745226e-03 2.88016740e-02 2.71931011e-03\n",
      "  5.59654378e-04 2.91260367e-04 1.50015168e-02 1.02992654e-02\n",
      "  3.61571112e-03 3.84694412e-02 3.21392640e-02 5.81101049e-03\n",
      "  3.14659555e-03 1.78246025e-03]]\n",
      "[[5.01873910e-01 1.14890330e-01 3.30559790e-01 8.21894109e-02\n",
      "  5.99471703e-02 2.48797797e-03 9.53073129e-02 1.08115515e-02\n",
      "  5.49139641e-03 3.90008427e-02 8.64466745e-03 1.38524789e-02\n",
      "  8.38588178e-02 2.97735687e-02 2.39477437e-02 5.81785589e-02\n",
      "  8.29641055e-03 3.24234329e-02 1.64914001e-02 3.56902257e-02\n",
      "  4.52030562e-02 1.88833978e-02 4.93673123e-02 6.64725574e-03\n",
      "  5.85150253e-03 1.72208436e-03 6.96560601e-03 1.20401587e-02\n",
      "  6.42477162e-03 8.78448933e-02 2.31018867e-02 1.08815276e-03\n",
      "  1.40712196e-02 4.03552409e-03 5.35340793e-03 5.38403867e-03\n",
      "  4.34629014e-03 1.99783826e-03 2.95502748e-02 6.25629211e-03\n",
      "  5.00632334e-04 1.27647526e-03 1.84096247e-02 6.15595840e-03\n",
      "  2.06255214e-03 4.52212133e-02 3.13074552e-02 3.70879075e-03\n",
      "  2.47691525e-03 4.49681887e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "         23826,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.47959316\n",
      "Comprehensiveness for iteration:  0.9596888\n",
      "Sufficency for iteration:  0.49973822\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9596888\n",
      "Comprehensiveness q1 (25% percentile):  0.9596887826919556\n",
      "Comprehensiveness q3 (75% percentile):  0.9596887826919556\n",
      "\n",
      "\n",
      "Sufficency Median:  0.49973822\n",
      "Sufficency q1 (25% percentile):  0.4997382164001465\n",
      "Sufficency q3 (75% percentile):  0.4997382164001465\n",
      "\n",
      "8\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5830adc9b25a467ebc433c31bd6eac11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.60s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\n",
      "indices_array: [[  0]\n",
      " [300]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "             1,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.5040929e-01 2.1886978e-01 2.8218806e-01 7.6862201e-02 2.3734713e-02\n",
      "  2.4260667e-03 3.7514672e-02 1.9397005e-02 2.6547899e-03 2.9294640e-02\n",
      "  6.5533407e-03 7.6329475e-03 1.0320821e-01 4.4530179e-02 9.4224652e-03\n",
      "  2.8506787e-02 7.5568906e-03 2.7939696e-02 6.4779650e-03 1.2748555e-02\n",
      "  1.7905703e-02 2.1284787e-02 6.1090361e-02 5.4757288e-03 8.7229628e-03\n",
      "  4.3751494e-04 2.5167360e-03 2.2577750e-02 4.1758143e-03 2.5102120e-02\n",
      "  2.1712257e-02 4.9755914e-04 5.6051603e-03 7.1981582e-03 1.5732672e-03\n",
      "  6.2019802e-03 1.9264955e-03 2.2758490e-03 3.2182936e-02 2.9412098e-03\n",
      "  4.5390232e-04 4.3881498e-04 1.8985786e-02 8.1995772e-03 2.1626656e-03\n",
      "  4.6468675e-02 3.5812672e-02 5.7269302e-03 2.7050544e-03 1.6312870e-03]]\n",
      "[[9.70871568e-01 1.96857512e-01 2.51062870e-01 7.13316053e-02\n",
      "  3.12236734e-02 2.70303944e-03 4.03510258e-02 2.63409074e-02\n",
      "  3.31422384e-03 2.57984865e-02 2.86850170e-03 1.07600195e-02\n",
      "  8.07873085e-02 3.26919779e-02 1.76847763e-02 4.17965129e-02\n",
      "  6.64963387e-03 2.40765214e-02 5.65298134e-03 1.28080100e-02\n",
      "  4.41987403e-02 1.66449156e-02 6.17092848e-02 9.39739123e-03\n",
      "  1.35578113e-02 4.55963309e-04 3.61788319e-03 1.79692637e-02\n",
      "  4.04899055e-03 2.28303559e-02 2.52821539e-02 1.04383787e-03\n",
      "  8.78512301e-03 6.42422121e-03 1.76444277e-03 6.76496234e-03\n",
      "  1.66552421e-03 1.51681947e-03 2.68320143e-02 4.00447892e-03\n",
      "  4.20759869e-04 4.74311440e-04 1.90336909e-02 5.74946404e-03\n",
      "  1.93307665e-03 4.21926752e-02 4.11955751e-02 5.94090857e-03\n",
      "  4.78152186e-03 1.86819804e-03]]\n",
      "[[9.5040929e-01 2.1886978e-01 2.8218806e-01 7.6862201e-02 2.3734713e-02\n",
      "  2.4260667e-03 3.7514672e-02 1.9397005e-02 2.6547899e-03 2.9294640e-02\n",
      "  6.5533407e-03 7.6329475e-03 1.0320821e-01 4.4530179e-02 9.4224652e-03\n",
      "  2.8506787e-02 7.5568906e-03 2.7939696e-02 6.4779650e-03 1.2748555e-02\n",
      "  1.7905703e-02 2.1284787e-02 6.1090361e-02 5.4757288e-03 8.7229628e-03\n",
      "  4.3751494e-04 2.5167360e-03 2.2577750e-02 4.1758143e-03 2.5102120e-02\n",
      "  2.1712257e-02 4.9755914e-04 5.6051603e-03 7.1981582e-03 1.5732672e-03\n",
      "  6.2019802e-03 1.9264955e-03 2.2758490e-03 3.2182936e-02 2.9412098e-03\n",
      "  4.5390232e-04 4.3881498e-04 1.8985786e-02 8.1995772e-03 2.1626656e-03\n",
      "  4.6468675e-02 3.5812672e-02 5.7269302e-03 2.7050544e-03 1.6312870e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "         13500,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.056425303\n",
      "Comprehensiveness for iteration:  0.90972257\n",
      "Sufficency for iteration:  0.06202474\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.90972257\n",
      "Comprehensiveness q1 (25% percentile):  0.9097225666046143\n",
      "Comprehensiveness q3 (75% percentile):  0.9097225666046143\n",
      "\n",
      "\n",
      "Sufficency Median:  0.06202474\n",
      "Sufficency q1 (25% percentile):  0.062024738639593124\n",
      "Sufficency q3 (75% percentile):  0.062024738639593124\n",
      "\n",
      "9\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33a493cc82446f1ac7178ff6b8f59a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.57s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\n",
      "indices_array: [[  0]\n",
      " [288]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,     1, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.62893307e-01 2.36812115e-01 3.01782697e-01 1.04460016e-01\n",
      "  7.11162016e-02 3.40096187e-03 6.74451143e-02 1.96805447e-02\n",
      "  4.05783812e-03 2.42054425e-02 5.36469044e-03 1.87931694e-02\n",
      "  6.17722347e-02 3.35289352e-02 1.33493561e-02 3.51746157e-02\n",
      "  7.66609283e-03 2.86745466e-02 1.20404307e-02 1.68647319e-02\n",
      "  3.38430777e-02 1.52897025e-02 7.10633770e-02 9.87464190e-03\n",
      "  1.09920679e-02 6.24464010e-04 4.46876371e-03 2.14421526e-02\n",
      "  5.06734895e-03 3.66507657e-02 2.39630174e-02 1.02970039e-03\n",
      "  1.32776974e-02 7.14935269e-03 3.25562013e-03 5.50108962e-03\n",
      "  2.62572593e-03 2.93911155e-03 2.15164870e-02 4.14871750e-03\n",
      "  1.10418361e-03 6.85283332e-04 1.39975911e-02 8.99126474e-03\n",
      "  3.30082350e-03 3.87634598e-02 4.95452359e-02 8.73558037e-03\n",
      "  3.80753144e-03 1.74206635e-03]]\n",
      "[[9.6272326e-01 2.0872436e-01 2.0768104e-01 6.2204476e-02 3.1139001e-02\n",
      "  2.4164359e-03 4.0291268e-02 2.4272133e-02 2.4664409e-03 2.5035692e-02\n",
      "  3.4459531e-03 1.1330151e-02 8.9294247e-02 2.9751360e-02 2.1418994e-02\n",
      "  3.7235573e-02 1.0772827e-02 2.9969798e-02 6.0212039e-03 2.3838090e-02\n",
      "  3.1699561e-02 2.2615632e-02 7.4100368e-02 1.2250562e-02 1.5510455e-02\n",
      "  4.6529132e-04 3.0135580e-03 2.1541389e-02 5.2182022e-03 2.9736130e-02\n",
      "  2.8196771e-02 1.1015271e-03 7.2070882e-03 7.4738148e-03 2.0605107e-03\n",
      "  5.4170559e-03 1.9758006e-03 2.6956059e-03 1.8429045e-02 2.5548413e-03\n",
      "  4.0224759e-04 3.9873712e-04 1.6772628e-02 7.2472175e-03 3.7783072e-03\n",
      "  6.6872716e-02 2.8846549e-02 6.4987782e-03 4.7445646e-03 1.2555054e-03]]\n",
      "[[9.62893307e-01 2.36812115e-01 3.01782697e-01 1.04460016e-01\n",
      "  7.11162016e-02 3.40096187e-03 6.74451143e-02 1.96805447e-02\n",
      "  4.05783812e-03 2.42054425e-02 5.36469044e-03 1.87931694e-02\n",
      "  6.17722347e-02 3.35289352e-02 1.33493561e-02 3.51746157e-02\n",
      "  7.66609283e-03 2.86745466e-02 1.20404307e-02 1.68647319e-02\n",
      "  3.38430777e-02 1.52897025e-02 7.10633770e-02 9.87464190e-03\n",
      "  1.09920679e-02 6.24464010e-04 4.46876371e-03 2.14421526e-02\n",
      "  5.06734895e-03 3.66507657e-02 2.39630174e-02 1.02970039e-03\n",
      "  1.32776974e-02 7.14935269e-03 3.25562013e-03 5.50108962e-03\n",
      "  2.62572593e-03 2.93911155e-03 2.15164870e-02 4.14871750e-03\n",
      "  1.10418361e-03 6.85283332e-04 1.39975911e-02 8.99126474e-03\n",
      "  3.30082350e-03 3.87634598e-02 4.95452359e-02 8.73558037e-03\n",
      "  3.80753144e-03 1.74206635e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1, 177,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.118119985\n",
      "Comprehensiveness for iteration:  0.9270176\n",
      "Sufficency for iteration:  0.12741935\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9270176\n",
      "Comprehensiveness q1 (25% percentile):  0.9270176291465759\n",
      "Comprehensiveness q3 (75% percentile):  0.9270176291465759\n",
      "\n",
      "\n",
      "Sufficency Median:  0.12741935\n",
      "Sufficency q1 (25% percentile):  0.1274193525314331\n",
      "Sufficency q3 (75% percentile):  0.1274193525314331\n",
      "\n",
      "0\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b769c4f25ba14163ab3a19c8b457e49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.58s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290]\n",
      "indices_array: [[  0]\n",
      " [290]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "             1,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[5.0499237e-01 9.4107203e-02 3.6021411e-01 7.1104020e-02 4.1332915e-02\n",
      "  3.0869995e-03 7.7264063e-02 1.1076939e-02 3.9816401e-03 3.4524310e-02\n",
      "  6.1169057e-03 1.8420653e-02 8.6687692e-02 2.9344613e-02 1.9271273e-02\n",
      "  6.1891582e-02 7.1453359e-03 2.1055890e-02 1.7404296e-02 3.6762416e-02\n",
      "  4.4309054e-02 1.1003126e-02 4.3198913e-02 4.7465465e-03 7.9740370e-03\n",
      "  1.1426085e-03 3.6551740e-03 9.4838990e-03 7.5575169e-03 5.0833814e-02\n",
      "  1.5304171e-02 8.2226441e-04 9.3759848e-03 3.5772878e-03 3.6464874e-03\n",
      "  5.6894124e-03 3.3190283e-03 1.3875715e-03 3.2707963e-02 4.6837293e-03\n",
      "  2.2156929e-04 7.7510922e-04 1.8145006e-02 5.1540434e-03 2.0805479e-03\n",
      "  4.3122437e-02 3.1114070e-02 4.4691926e-03 2.4920250e-03 3.5889936e-03]]\n",
      "[[9.72672641e-01 1.47747934e-01 2.85694659e-01 7.06928670e-02\n",
      "  2.38187183e-02 2.20619072e-03 4.49727811e-02 1.78510547e-02\n",
      "  2.13242695e-03 1.30815292e-02 3.79103399e-03 1.00145917e-02\n",
      "  1.06354862e-01 3.04031838e-02 1.34299276e-02 2.77137179e-02\n",
      "  5.64305903e-03 3.27760428e-02 7.60820881e-03 1.67747512e-02\n",
      "  3.16389352e-02 1.44860474e-02 5.40997684e-02 1.05226645e-02\n",
      "  1.26793748e-02 3.92051152e-04 2.41262489e-03 1.46898311e-02\n",
      "  4.81323246e-03 3.08001079e-02 1.92569215e-02 4.91512357e-04\n",
      "  7.71845272e-03 4.91352612e-03 2.15162965e-03 4.45045158e-03\n",
      "  2.04476435e-03 1.94594858e-03 3.83876637e-02 2.94888113e-03\n",
      "  3.89635068e-04 3.56709206e-04 1.73099712e-02 7.04056583e-03\n",
      "  1.76832289e-03 5.15216738e-02 3.51407640e-02 6.64714258e-03\n",
      "  6.52878406e-03 1.11294445e-03]]\n",
      "[[5.0499237e-01 9.4107203e-02 3.6021411e-01 7.1104020e-02 4.1332915e-02\n",
      "  3.0869995e-03 7.7264063e-02 1.1076939e-02 3.9816401e-03 3.4524310e-02\n",
      "  6.1169057e-03 1.8420653e-02 8.6687692e-02 2.9344613e-02 1.9271273e-02\n",
      "  6.1891582e-02 7.1453359e-03 2.1055890e-02 1.7404296e-02 3.6762416e-02\n",
      "  4.4309054e-02 1.1003126e-02 4.3198913e-02 4.7465465e-03 7.9740370e-03\n",
      "  1.1426085e-03 3.6551740e-03 9.4838990e-03 7.5575169e-03 5.0833814e-02\n",
      "  1.5304171e-02 8.2226441e-04 9.3759848e-03 3.5772878e-03 3.6464874e-03\n",
      "  5.6894124e-03 3.3190283e-03 1.3875715e-03 3.2707963e-02 4.6837293e-03\n",
      "  2.2156929e-04 7.7510922e-04 1.8145006e-02 5.1540434e-03 2.0805479e-03\n",
      "  4.3122437e-02 3.1114070e-02 4.4691926e-03 2.4920250e-03 3.5889936e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "         23826,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.48845753\n",
      "Comprehensiveness for iteration:  1.0134913\n",
      "Sufficency for iteration:  0.48195535\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0134913\n",
      "Comprehensiveness q1 (25% percentile):  1.0134912729263306\n",
      "Comprehensiveness q3 (75% percentile):  1.0134912729263306\n",
      "\n",
      "\n",
      "Sufficency Median:  0.48195535\n",
      "Sufficency q1 (25% percentile):  0.481955349445343\n",
      "Sufficency q3 (75% percentile):  0.481955349445343\n",
      "\n",
      "1\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f234efa5e05c4b1a91647aab5ba2653e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.60s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308]\n",
      "indices_array: [[  0]\n",
      " [308]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,     1,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.81780469e-01 1.23604454e-01 2.29467690e-01 8.19057524e-02\n",
      "  1.69986431e-02 2.19885097e-03 4.54348288e-02 2.35648733e-02\n",
      "  2.77982117e-03 2.21640933e-02 5.02485828e-03 1.44214779e-02\n",
      "  1.45005718e-01 2.38131490e-02 1.74979791e-02 2.95214653e-02\n",
      "  9.14574787e-03 3.54095660e-02 1.05105527e-02 1.98998768e-02\n",
      "  3.52640562e-02 2.72690896e-02 7.45332092e-02 9.72374063e-03\n",
      "  1.40625490e-02 4.64756769e-04 6.01157965e-03 2.41543241e-02\n",
      "  6.73266593e-03 2.63709147e-02 2.36186441e-02 7.60912779e-04\n",
      "  9.80581157e-03 8.68718885e-03 2.00203247e-03 8.76540970e-03\n",
      "  1.70797238e-03 1.82670460e-03 4.23351601e-02 4.04520426e-03\n",
      "  4.86058212e-04 6.04500179e-04 1.89449377e-02 1.48769906e-02\n",
      "  3.93556245e-03 5.48982210e-02 2.93332357e-02 8.36071093e-03\n",
      "  4.97204717e-03 1.90978951e-03]]\n",
      "[[9.5431519e-01 1.5037106e-01 2.2680804e-01 7.8370772e-02 2.8667422e-02\n",
      "  4.7748662e-03 6.6952430e-02 2.0284254e-02 3.4089359e-03 3.4222577e-02\n",
      "  4.4628661e-03 2.6712375e-02 1.0720503e-01 3.0826617e-02 1.8628992e-02\n",
      "  5.6667157e-02 6.1472128e-03 3.7598677e-02 8.9203417e-03 1.4583066e-02\n",
      "  3.5354406e-02 1.7290995e-02 7.8049831e-02 1.0613820e-02 9.6153086e-03\n",
      "  6.1896554e-04 2.9526956e-03 2.8234052e-02 8.0073075e-03 3.1615075e-02\n",
      "  2.7351124e-02 7.9127483e-04 1.1637019e-02 5.0844322e-03 2.4486913e-03\n",
      "  7.4797068e-03 2.3165364e-03 1.5280546e-03 2.9567080e-02 4.5841639e-03\n",
      "  6.9257134e-04 5.5143575e-04 1.7493267e-02 9.2232935e-03 2.3056187e-03\n",
      "  5.6824561e-02 3.7193321e-02 7.1857111e-03 5.8856257e-03 1.8814310e-03]]\n",
      "[[9.81780469e-01 1.23604454e-01 2.29467690e-01 8.19057524e-02\n",
      "  1.69986431e-02 2.19885097e-03 4.54348288e-02 2.35648733e-02\n",
      "  2.77982117e-03 2.21640933e-02 5.02485828e-03 1.44214779e-02\n",
      "  1.45005718e-01 2.38131490e-02 1.74979791e-02 2.95214653e-02\n",
      "  9.14574787e-03 3.54095660e-02 1.05105527e-02 1.98998768e-02\n",
      "  3.52640562e-02 2.72690896e-02 7.45332092e-02 9.72374063e-03\n",
      "  1.40625490e-02 4.64756769e-04 6.01157965e-03 2.41543241e-02\n",
      "  6.73266593e-03 2.63709147e-02 2.36186441e-02 7.60912779e-04\n",
      "  9.80581157e-03 8.68718885e-03 2.00203247e-03 8.76540970e-03\n",
      "  1.70797238e-03 1.82670460e-03 4.23351601e-02 4.04520426e-03\n",
      "  4.86058212e-04 6.04500179e-04 1.89449377e-02 1.48769906e-02\n",
      "  3.93556245e-03 5.48982210e-02 2.93332357e-02 8.36071093e-03\n",
      "  4.97204717e-03 1.90978951e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "         168,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.0691035\n",
      "Comprehensiveness for iteration:  0.96265584\n",
      "Sufficency for iteration:  0.07178422\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.96265584\n",
      "Comprehensiveness q1 (25% percentile):  0.9626558423042297\n",
      "Comprehensiveness q3 (75% percentile):  0.9626558423042297\n",
      "\n",
      "\n",
      "Sufficency Median:  0.07178422\n",
      "Sufficency q1 (25% percentile):  0.07178422063589096\n",
      "Sufficency q3 (75% percentile):  0.07178422063589096\n",
      "\n",
      "2\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5a689a559c47ca99c573eccd015938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.73s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295]\n",
      "indices_array: [[  0]\n",
      " [295]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,     1,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6324801e-01 2.8196812e-01 2.6598781e-01 6.0206898e-02 3.6830854e-02\n",
      "  3.6558665e-03 4.4584654e-02 2.0526988e-02 2.0699205e-03 2.9027576e-02\n",
      "  5.4980675e-03 1.1320130e-02 6.5487087e-02 4.1735157e-02 2.1121740e-02\n",
      "  5.2056067e-02 1.1770464e-02 2.5023440e-02 8.6199436e-03 2.6775166e-02\n",
      "  1.7066374e-02 2.5031323e-02 7.1608126e-02 1.0444066e-02 1.0691811e-02\n",
      "  3.2344850e-04 3.0417182e-03 2.5758279e-02 4.9430723e-03 3.6617704e-02\n",
      "  2.4320813e-02 1.5301221e-03 8.5037649e-03 7.2834827e-03 2.3571858e-03\n",
      "  6.9121732e-03 2.3033845e-03 1.8935133e-03 3.3235885e-02 2.2930466e-03\n",
      "  6.0958986e-04 4.5244244e-04 2.4102844e-02 1.2453177e-02 3.0636617e-03\n",
      "  6.3956566e-02 4.6534896e-02 5.3588944e-03 4.6213618e-03 2.1812192e-03]]\n",
      "[[9.78984773e-01 1.93321958e-01 4.07639354e-01 6.41686693e-02\n",
      "  3.17472741e-02 1.88582018e-03 5.79570383e-02 1.79352667e-02\n",
      "  2.07141903e-03 2.10369732e-02 3.30790901e-03 6.71166927e-03\n",
      "  1.02987215e-01 3.30455676e-02 1.70073453e-02 3.24734747e-02\n",
      "  5.62913064e-03 3.29181328e-02 1.07403947e-02 1.60508063e-02\n",
      "  3.08121964e-02 2.05829404e-02 6.22989908e-02 8.04554205e-03\n",
      "  1.10102575e-02 3.47192516e-04 2.54989695e-03 2.12312397e-02\n",
      "  4.88513196e-03 2.58374400e-02 3.18507738e-02 5.01460512e-04\n",
      "  7.17900554e-03 6.54500769e-03 3.36773903e-03 5.26700681e-03\n",
      "  1.66879583e-03 1.24755153e-03 4.09432501e-02 2.14810995e-03\n",
      "  4.75356996e-04 3.14289005e-04 1.59989409e-02 9.09927487e-03\n",
      "  3.14987404e-03 3.86784337e-02 3.44456546e-02 5.84830251e-03\n",
      "  3.29732220e-03 1.36808318e-03]]\n",
      "[[9.6324801e-01 2.8196812e-01 2.6598781e-01 6.0206898e-02 3.6830854e-02\n",
      "  3.6558665e-03 4.4584654e-02 2.0526988e-02 2.0699205e-03 2.9027576e-02\n",
      "  5.4980675e-03 1.1320130e-02 6.5487087e-02 4.1735157e-02 2.1121740e-02\n",
      "  5.2056067e-02 1.1770464e-02 2.5023440e-02 8.6199436e-03 2.6775166e-02\n",
      "  1.7066374e-02 2.5031323e-02 7.1608126e-02 1.0444066e-02 1.0691811e-02\n",
      "  3.2344850e-04 3.0417182e-03 2.5758279e-02 4.9430723e-03 3.6617704e-02\n",
      "  2.4320813e-02 1.5301221e-03 8.5037649e-03 7.2834827e-03 2.3571858e-03\n",
      "  6.9121732e-03 2.3033845e-03 1.8935133e-03 3.3235885e-02 2.2930466e-03\n",
      "  6.0958986e-04 4.5244244e-04 2.4102844e-02 1.2453177e-02 3.0636617e-03\n",
      "  6.3956566e-02 4.6534896e-02 5.3588944e-03 4.6213618e-03 2.1812192e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1, 185,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.18289092\n",
      "Comprehensiveness for iteration:  1.022076\n",
      "Sufficency for iteration:  0.17894062\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.022076\n",
      "Comprehensiveness q1 (25% percentile):  1.0220760107040405\n",
      "Comprehensiveness q3 (75% percentile):  1.0220760107040405\n",
      "\n",
      "\n",
      "Sufficency Median:  0.17894062\n",
      "Sufficency q1 (25% percentile):  0.17894062399864197\n",
      "Sufficency q3 (75% percentile):  0.17894062399864197\n",
      "\n",
      "3\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264155c4e1e64b0ea5cb15a3511e9519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:45, 45.31s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296]\n",
      "indices_array: [[  0]\n",
      " [296]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,     1,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7320276e-01 1.3272975e-01 2.5235751e-01 7.5022489e-02 2.6980570e-02\n",
      "  2.2578333e-03 7.0026122e-02 1.9465001e-02 2.6977961e-03 1.3720952e-02\n",
      "  2.8051669e-03 1.0329288e-02 1.0315727e-01 2.7252723e-02 1.2244187e-02\n",
      "  2.3656722e-02 8.1784129e-03 3.0719221e-02 9.3566366e-03 2.3195056e-02\n",
      "  2.4425954e-02 1.7185725e-02 3.7560247e-02 5.4794899e-03 1.2250804e-02\n",
      "  2.1595642e-04 1.9603905e-03 2.5305413e-02 5.1944936e-03 2.5135525e-02\n",
      "  2.2977985e-02 3.8035691e-04 6.7626596e-03 3.6421001e-03 3.1010099e-03\n",
      "  6.8313177e-03 1.8158021e-03 1.9562542e-03 2.6271556e-02 2.0945449e-03\n",
      "  4.4969848e-04 2.0857740e-04 1.3825784e-02 6.8468605e-03 1.7300870e-03\n",
      "  5.8972482e-02 3.6288209e-02 6.4200494e-03 3.6914831e-03 9.1189495e-04]]\n",
      "[[9.6547747e-01 1.3526420e-01 3.2316071e-01 5.8861583e-02 2.3296839e-02\n",
      "  1.5577942e-03 5.0659243e-02 2.1701524e-02 3.8508151e-03 2.7914520e-02\n",
      "  2.9822402e-03 9.2225363e-03 1.0151818e-01 4.2545971e-02 1.3289172e-02\n",
      "  3.5033256e-02 7.7624787e-03 2.2914670e-02 9.2065334e-03 1.2638855e-02\n",
      "  3.1985067e-02 1.6097292e-02 6.4720578e-02 1.2207461e-02 1.3444727e-02\n",
      "  4.9865071e-04 1.7096163e-03 1.6478738e-02 6.2472005e-03 2.9190445e-02\n",
      "  3.2024436e-02 6.7260378e-04 6.7719407e-03 7.5940485e-03 2.6221592e-03\n",
      "  6.2161884e-03 1.6621557e-03 2.9247510e-03 3.5653293e-02 2.9517158e-03\n",
      "  3.4814113e-04 4.3613999e-04 1.5496685e-02 8.1413332e-03 2.4658591e-03\n",
      "  3.9309103e-02 3.9268184e-02 9.0603782e-03 5.3234296e-03 1.2029994e-03]]\n",
      "[[9.7320276e-01 1.3272975e-01 2.5235751e-01 7.5022489e-02 2.6980570e-02\n",
      "  2.2578333e-03 7.0026122e-02 1.9465001e-02 2.6977961e-03 1.3720952e-02\n",
      "  2.8051669e-03 1.0329288e-02 1.0315727e-01 2.7252723e-02 1.2244187e-02\n",
      "  2.3656722e-02 8.1784129e-03 3.0719221e-02 9.3566366e-03 2.3195056e-02\n",
      "  2.4425954e-02 1.7185725e-02 3.7560247e-02 5.4794899e-03 1.2250804e-02\n",
      "  2.1595642e-04 1.9603905e-03 2.5305413e-02 5.1944936e-03 2.5135525e-02\n",
      "  2.2977985e-02 3.8035691e-04 6.7626596e-03 3.6421001e-03 3.1010099e-03\n",
      "  6.8313177e-03 1.8158021e-03 1.9562542e-03 2.6271556e-02 2.0945449e-03\n",
      "  4.4969848e-04 2.0857740e-04 1.3825784e-02 6.8468605e-03 1.7300870e-03\n",
      "  5.8972482e-02 3.6288209e-02 6.4200494e-03 3.6914831e-03 9.1189495e-04]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1, 1126,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.088048644\n",
      "Comprehensiveness for iteration:  0.9835128\n",
      "Sufficency for iteration:  0.08952466\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9835128\n",
      "Comprehensiveness q1 (25% percentile):  0.983512818813324\n",
      "Comprehensiveness q3 (75% percentile):  0.983512818813324\n",
      "\n",
      "\n",
      "Sufficency Median:  0.08952466\n",
      "Sufficency q1 (25% percentile):  0.08952465653419495\n",
      "Sufficency q3 (75% percentile):  0.08952465653419495\n",
      "\n",
      "4\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb98caa8bf554bdcbb200139bc3b3711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.60s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310]\n",
      "indices_array: [[  0]\n",
      " [310]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "             1,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.8096597e-01 2.7055138e-01 2.3622955e-01 6.2255856e-02 2.0972528e-02\n",
      "  2.8667892e-03 4.9730010e-02 2.5283087e-02 2.0327980e-03 1.8038861e-02\n",
      "  4.8498488e-03 1.2561365e-02 1.2040217e-01 2.6374161e-02 1.7566133e-02\n",
      "  3.0000754e-02 8.8799829e-03 2.0498514e-02 8.8697495e-03 2.1804065e-02\n",
      "  1.8528875e-02 1.2470008e-02 4.2607434e-02 1.1205910e-02 9.1926986e-03\n",
      "  4.5928356e-04 4.6927384e-03 2.2465477e-02 4.7240625e-03 4.2661268e-02\n",
      "  2.9394576e-02 9.8622718e-04 7.4166781e-03 7.1567385e-03 3.1741941e-03\n",
      "  4.6745599e-03 2.2112885e-03 1.7080544e-03 2.3952194e-02 4.3543186e-03\n",
      "  5.3358270e-04 3.3309706e-04 1.9849876e-02 8.6154900e-03 3.2894427e-03\n",
      "  3.8179774e-02 2.9721262e-02 6.3445703e-03 5.6143845e-03 1.5038950e-03]]\n",
      "[[9.6968061e-01 1.8779647e-01 2.8551421e-01 1.0752055e-01 2.5574312e-02\n",
      "  3.3285918e-03 4.8193891e-02 2.6610943e-02 2.9651765e-03 1.9316476e-02\n",
      "  4.7659199e-03 1.6356084e-02 7.8332365e-02 4.1629635e-02 1.6927842e-02\n",
      "  3.9084882e-02 7.3935450e-03 2.7443407e-02 9.9978615e-03 1.2314930e-02\n",
      "  2.4344724e-02 1.8226955e-02 4.8639167e-02 7.0894733e-03 9.0114726e-03\n",
      "  5.0516659e-04 4.2512571e-03 1.8943347e-02 6.9395355e-03 4.6479221e-02\n",
      "  2.8244792e-02 9.7715633e-04 9.4294371e-03 9.2077255e-03 2.1960898e-03\n",
      "  7.3565645e-03 1.5618370e-03 1.8911986e-03 3.7175480e-02 5.0811870e-03\n",
      "  4.1952569e-04 4.6647375e-04 1.4917074e-02 7.5623216e-03 3.0368012e-03\n",
      "  3.5002220e-02 3.0603098e-02 9.2312414e-03 5.2112192e-03 1.5663503e-03]]\n",
      "[[9.8096597e-01 2.7055138e-01 2.3622955e-01 6.2255856e-02 2.0972528e-02\n",
      "  2.8667892e-03 4.9730010e-02 2.5283087e-02 2.0327980e-03 1.8038861e-02\n",
      "  4.8498488e-03 1.2561365e-02 1.2040217e-01 2.6374161e-02 1.7566133e-02\n",
      "  3.0000754e-02 8.8799829e-03 2.0498514e-02 8.8697495e-03 2.1804065e-02\n",
      "  1.8528875e-02 1.2470008e-02 4.2607434e-02 1.1205910e-02 9.1926986e-03\n",
      "  4.5928356e-04 4.6927384e-03 2.2465477e-02 4.7240625e-03 4.2661268e-02\n",
      "  2.9394576e-02 9.8622718e-04 7.4166781e-03 7.1567385e-03 3.1741941e-03\n",
      "  4.6745599e-03 2.2112885e-03 1.7080544e-03 2.3952194e-02 4.3543186e-03\n",
      "  5.3358270e-04 3.3309706e-04 1.9849876e-02 8.6154900e-03 3.2894427e-03\n",
      "  3.8179774e-02 2.9721262e-02 6.3445703e-03 5.6143845e-03 1.5038950e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1, 173,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.11520019\n",
      "Comprehensiveness for iteration:  0.96967244\n",
      "Sufficency for iteration:  0.1188032\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.96967244\n",
      "Comprehensiveness q1 (25% percentile):  0.969672441482544\n",
      "Comprehensiveness q3 (75% percentile):  0.969672441482544\n",
      "\n",
      "\n",
      "Sufficency Median:  0.1188032\n",
      "Sufficency q1 (25% percentile):  0.11880320310592651\n",
      "Sufficency q3 (75% percentile):  0.11880320310592651\n",
      "\n",
      "5\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518a7aa440054a3aa9d64532121cbe60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.67s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\n",
      "indices_array: [[  0]\n",
      " [288]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,     1, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.66115296e-01 2.28346288e-01 3.44031841e-01 8.76947939e-02\n",
      "  3.63129787e-02 3.89584596e-03 5.62700890e-02 3.22372131e-02\n",
      "  2.56312499e-03 3.30870599e-02 3.54748778e-03 1.02202250e-02\n",
      "  7.44191781e-02 3.19323726e-02 1.71341840e-02 3.20235342e-02\n",
      "  7.62413908e-03 3.22103240e-02 9.20730270e-03 1.72346104e-02\n",
      "  3.88292074e-02 3.01801562e-02 6.04785271e-02 8.75490904e-03\n",
      "  8.48445669e-03 3.89075722e-04 3.20930500e-03 2.64845770e-02\n",
      "  5.67705790e-03 3.43365222e-02 3.20068561e-02 1.46606320e-03\n",
      "  1.32452380e-02 5.04654879e-03 3.83362710e-03 6.71742531e-03\n",
      "  1.65043818e-03 1.96642848e-03 3.99750844e-02 7.40961498e-03\n",
      "  9.87895066e-04 5.24475647e-04 1.85866561e-02 1.26026785e-02\n",
      "  3.24328803e-03 4.44930568e-02 3.21748070e-02 5.59985451e-03\n",
      "  5.29929297e-03 2.19607097e-03]]\n",
      "[[9.7370559e-01 1.3343638e-01 3.0419186e-01 7.3181532e-02 2.9694585e-02\n",
      "  2.1962279e-03 4.7272488e-02 2.5157936e-02 3.5658213e-03 1.8318150e-02\n",
      "  3.6656586e-03 1.0262469e-02 7.2418928e-02 2.8546168e-02 1.8164214e-02\n",
      "  2.6564749e-02 1.1640556e-02 2.0571653e-02 4.9267169e-03 1.1199935e-02\n",
      "  2.9663006e-02 2.1521663e-02 5.6289602e-02 7.8639463e-03 1.0681949e-02\n",
      "  5.2845164e-04 3.4113536e-03 2.3365214e-02 4.1371179e-03 3.2212619e-02\n",
      "  2.6281223e-02 6.9443585e-04 6.2386543e-03 7.3988908e-03 1.2011222e-03\n",
      "  4.0262318e-03 1.4924393e-03 1.6724541e-03 2.5309136e-02 4.2202324e-03\n",
      "  2.5810828e-04 4.0903117e-04 1.7023297e-02 8.4015168e-03 2.7508943e-03\n",
      "  4.3934993e-02 3.5284106e-02 5.2923197e-03 5.2645514e-03 1.7212435e-03]]\n",
      "[[9.66115296e-01 2.28346288e-01 3.44031841e-01 8.76947939e-02\n",
      "  3.63129787e-02 3.89584596e-03 5.62700890e-02 3.22372131e-02\n",
      "  2.56312499e-03 3.30870599e-02 3.54748778e-03 1.02202250e-02\n",
      "  7.44191781e-02 3.19323726e-02 1.71341840e-02 3.20235342e-02\n",
      "  7.62413908e-03 3.22103240e-02 9.20730270e-03 1.72346104e-02\n",
      "  3.88292074e-02 3.01801562e-02 6.04785271e-02 8.75490904e-03\n",
      "  8.48445669e-03 3.89075722e-04 3.20930500e-03 2.64845770e-02\n",
      "  5.67705790e-03 3.43365222e-02 3.20068561e-02 1.46606320e-03\n",
      "  1.32452380e-02 5.04654879e-03 3.83362710e-03 6.71742531e-03\n",
      "  1.65043818e-03 1.96642848e-03 3.99750844e-02 7.40961498e-03\n",
      "  9.87895066e-04 5.24475647e-04 1.85866561e-02 1.26026785e-02\n",
      "  3.24328803e-03 4.44930568e-02 3.21748070e-02 5.59985451e-03\n",
      "  5.29929297e-03 2.19607097e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1, 177,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.11343779\n",
      "Comprehensiveness for iteration:  1.0325124\n",
      "Sufficency for iteration:  0.109865785\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0325124\n",
      "Comprehensiveness q1 (25% percentile):  1.0325124263763428\n",
      "Comprehensiveness q3 (75% percentile):  1.0325124263763428\n",
      "\n",
      "\n",
      "Sufficency Median:  0.109865785\n",
      "Sufficency q1 (25% percentile):  0.10986578464508057\n",
      "Sufficency q3 (75% percentile):  0.10986578464508057\n",
      "\n",
      "6\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782e518f80c14b59b4b9f4ce7441c837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.50s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[297]\n",
      "indices_array: [[  0]\n",
      " [297]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,     1,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.5595115e-01 1.9536063e-01 2.9160860e-01 8.6208083e-02 3.0367523e-02\n",
      "  2.5837154e-03 5.4545101e-02 1.9548353e-02 2.2270945e-03 2.6953476e-02\n",
      "  3.9272136e-03 1.2791008e-02 8.6666271e-02 3.4437466e-02 1.8538740e-02\n",
      "  2.6575629e-02 7.4171093e-03 2.8951967e-02 7.3895995e-03 1.1728539e-02\n",
      "  2.9794220e-02 1.4742224e-02 6.5217935e-02 7.5263791e-03 6.8956795e-03\n",
      "  6.0894445e-04 3.5849579e-03 1.9562328e-02 2.9898866e-03 2.7553497e-02\n",
      "  2.3119032e-02 7.4017013e-04 5.7904464e-03 4.6363678e-03 3.8018350e-03\n",
      "  3.4160712e-03 1.6391502e-03 1.4310817e-03 2.2927416e-02 3.5435760e-03\n",
      "  5.7982776e-04 7.7960710e-04 1.6324852e-02 8.9974701e-03 2.0929489e-03\n",
      "  5.0959036e-02 4.5287468e-02 8.8158073e-03 4.9446882e-03 1.0803955e-03]]\n",
      "[[9.69456911e-01 2.14865044e-01 2.56987154e-01 7.03833327e-02\n",
      "  2.72384286e-02 2.00532470e-03 5.34189790e-02 2.53771003e-02\n",
      "  1.75163604e-03 1.56079736e-02 3.60222347e-03 1.16548995e-02\n",
      "  8.43093395e-02 4.43646386e-02 7.79759092e-03 3.87112498e-02\n",
      "  1.02928523e-02 2.81360950e-02 9.83028766e-03 2.18724869e-02\n",
      "  2.92595830e-02 2.15737037e-02 5.55276535e-02 1.00414604e-02\n",
      "  1.28376940e-02 8.01751565e-04 2.90591246e-03 2.32012887e-02\n",
      "  5.16102323e-03 3.45751829e-02 2.37856805e-02 7.61531584e-04\n",
      "  1.08233588e-02 7.36873690e-03 3.55955306e-03 5.06768562e-03\n",
      "  1.91860925e-03 1.84324000e-03 2.84594130e-02 2.98347441e-03\n",
      "  4.08348016e-04 3.84066137e-04 1.95595920e-02 9.73086525e-03\n",
      "  3.82143119e-03 3.47088389e-02 3.50879245e-02 1.03287045e-02\n",
      "  5.22304559e-03 1.66420871e-03]]\n",
      "[[9.5595115e-01 1.9536063e-01 2.9160860e-01 8.6208083e-02 3.0367523e-02\n",
      "  2.5837154e-03 5.4545101e-02 1.9548353e-02 2.2270945e-03 2.6953476e-02\n",
      "  3.9272136e-03 1.2791008e-02 8.6666271e-02 3.4437466e-02 1.8538740e-02\n",
      "  2.6575629e-02 7.4171093e-03 2.8951967e-02 7.3895995e-03 1.1728539e-02\n",
      "  2.9794220e-02 1.4742224e-02 6.5217935e-02 7.5263791e-03 6.8956795e-03\n",
      "  6.0894445e-04 3.5849579e-03 1.9562328e-02 2.9898866e-03 2.7553497e-02\n",
      "  2.3119032e-02 7.4017013e-04 5.7904464e-03 4.6363678e-03 3.8018350e-03\n",
      "  3.4160712e-03 1.6391502e-03 1.4310817e-03 2.2927416e-02 3.5435760e-03\n",
      "  5.7982776e-04 7.7960710e-04 1.6324852e-02 8.9974701e-03 2.0929489e-03\n",
      "  5.0959036e-02 4.5287468e-02 8.8158073e-03 4.9446882e-03 1.0803955e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1, 8816,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.057432324\n",
      "Comprehensiveness for iteration:  0.9886606\n",
      "Sufficency for iteration:  0.058091044\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9886606\n",
      "Comprehensiveness q1 (25% percentile):  0.9886605739593506\n",
      "Comprehensiveness q3 (75% percentile):  0.9886605739593506\n",
      "\n",
      "\n",
      "Sufficency Median:  0.058091044\n",
      "Sufficency q1 (25% percentile):  0.058091044425964355\n",
      "Sufficency q3 (75% percentile):  0.058091044425964355\n",
      "\n",
      "7\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdce534de3564dcda682231fa7133d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.51s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309]\n",
      "indices_array: [[  0]\n",
      " [309]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,     1,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6249205e-01 1.6569021e-01 2.2556052e-01 4.4321276e-02 3.2103445e-02\n",
      "  3.6093809e-03 4.4017233e-02 2.7577089e-02 3.2441511e-03 2.0918965e-02\n",
      "  4.6155420e-03 1.3360502e-02 9.5671624e-02 3.8879905e-02 1.5930325e-02\n",
      "  3.3299297e-02 1.7020233e-02 3.1360738e-02 1.0870883e-02 2.2025038e-02\n",
      "  3.6318626e-02 2.3506707e-02 5.6430805e-02 7.6471046e-03 8.5281022e-03\n",
      "  6.1257184e-04 5.9693251e-03 2.4434820e-02 3.8030003e-03 3.4338079e-02\n",
      "  3.0734189e-02 9.9351234e-04 9.5185507e-03 4.5572170e-03 3.7391274e-03\n",
      "  6.6860393e-03 2.6587129e-03 1.4755299e-03 2.3271045e-02 2.9772045e-03\n",
      "  4.6238009e-04 4.4608742e-04 1.3782395e-02 9.1299750e-03 2.8263156e-03\n",
      "  4.5690231e-02 3.8141105e-02 6.6442024e-03 5.8874311e-03 1.1624763e-03]]\n",
      "[[9.5953238e-01 2.1165183e-01 2.5872242e-01 8.2077704e-02 3.9456714e-02\n",
      "  3.5347037e-03 5.4444432e-02 1.8593384e-02 3.4355135e-03 2.4392309e-02\n",
      "  3.0552291e-03 1.5026940e-02 1.1220537e-01 3.0402962e-02 1.4067133e-02\n",
      "  4.9125522e-02 7.7985022e-03 2.7193857e-02 1.0281623e-02 1.2544619e-02\n",
      "  3.2074980e-02 2.3842141e-02 6.7572929e-02 1.2852363e-02 9.2865517e-03\n",
      "  5.8395381e-04 2.6562319e-03 1.8502567e-02 4.2849821e-03 3.0174706e-02\n",
      "  3.1175887e-02 9.1886474e-04 1.2110073e-02 5.2159452e-03 2.7122237e-03\n",
      "  6.0914704e-03 1.6680427e-03 1.3212558e-03 2.8894430e-02 3.2195768e-03\n",
      "  5.4883509e-04 3.0979692e-04 1.7453413e-02 9.6708927e-03 2.2644363e-03\n",
      "  3.5744209e-02 4.9962226e-02 6.3445736e-03 2.8718822e-03 1.6010168e-03]]\n",
      "[[9.6249205e-01 1.6569021e-01 2.2556052e-01 4.4321276e-02 3.2103445e-02\n",
      "  3.6093809e-03 4.4017233e-02 2.7577089e-02 3.2441511e-03 2.0918965e-02\n",
      "  4.6155420e-03 1.3360502e-02 9.5671624e-02 3.8879905e-02 1.5930325e-02\n",
      "  3.3299297e-02 1.7020233e-02 3.1360738e-02 1.0870883e-02 2.2025038e-02\n",
      "  3.6318626e-02 2.3506707e-02 5.6430805e-02 7.6471046e-03 8.5281022e-03\n",
      "  6.1257184e-04 5.9693251e-03 2.4434820e-02 3.8030003e-03 3.4338079e-02\n",
      "  3.0734189e-02 9.9351234e-04 9.5185507e-03 4.5572170e-03 3.7391274e-03\n",
      "  6.6860393e-03 2.6587129e-03 1.4755299e-03 2.3271045e-02 2.9772045e-03\n",
      "  4.6238009e-04 4.4608742e-04 1.3782395e-02 9.1299750e-03 2.8263156e-03\n",
      "  4.5690231e-02 3.8141105e-02 6.6442024e-03 5.8874311e-03 1.1624763e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1, 1118,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.07895278\n",
      "Comprehensiveness for iteration:  0.9997731\n",
      "Sufficency for iteration:  0.0789707\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  0.9997731\n",
      "Comprehensiveness q1 (25% percentile):  0.9997730851173401\n",
      "Comprehensiveness q3 (75% percentile):  0.9997730851173401\n",
      "\n",
      "\n",
      "Sufficency Median:  0.0789707\n",
      "Sufficency q1 (25% percentile):  0.07897070050239563\n",
      "Sufficency q3 (75% percentile):  0.07897070050239563\n",
      "\n",
      "8\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719d81d888d748519e900b0cff89ae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.66s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[312]\n",
      "indices_array: [[  0]\n",
      " [312]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,  1126,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,     1,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.6233428e-01 2.0096281e-01 2.3323011e-01 9.1673449e-02 4.0219955e-02\n",
      "  2.6912764e-03 5.6986183e-02 4.0712830e-02 3.5761627e-03 3.3900749e-02\n",
      "  5.9443903e-03 1.3436823e-02 1.3769838e-01 3.4276400e-02 1.1441193e-02\n",
      "  2.4423603e-02 1.2502227e-02 5.3462781e-02 9.4033154e-03 2.4498127e-02\n",
      "  7.1465254e-02 2.7522925e-02 7.1233228e-02 1.0221729e-02 2.2217367e-02\n",
      "  8.7305316e-04 3.8653626e-03 2.8155506e-02 8.5726157e-03 4.6076752e-02\n",
      "  3.9658930e-02 7.3386863e-04 8.7894471e-03 9.9954829e-03 3.9879009e-03\n",
      "  6.9194594e-03 1.6460378e-03 1.8839516e-03 3.0991154e-02 3.7637451e-03\n",
      "  7.3796988e-04 4.9279403e-04 1.8200329e-02 1.0167997e-02 3.1312034e-03\n",
      "  4.0111348e-02 3.8744453e-02 1.0793096e-02 5.7690297e-03 2.1932651e-03]]\n",
      "[[9.7122443e-01 2.3302522e-01 2.6718351e-01 9.1579907e-02 2.5656041e-02\n",
      "  3.2907012e-03 3.7324440e-02 2.1164337e-02 3.7725717e-03 2.6773376e-02\n",
      "  2.5014956e-03 1.2168342e-02 1.2026485e-01 4.4727959e-02 2.5241647e-02\n",
      "  6.0344126e-02 7.5319698e-03 2.8391719e-02 1.0573396e-02 1.6163206e-02\n",
      "  3.5025831e-02 2.9811520e-02 7.0174895e-02 8.9319460e-03 1.5351957e-02\n",
      "  4.5555190e-04 3.7801922e-03 2.9047118e-02 6.4616832e-03 3.4067962e-02\n",
      "  3.2820333e-02 9.4237179e-04 8.0832513e-03 8.2438365e-03 3.4854775e-03\n",
      "  6.4982730e-03 1.3943048e-03 2.1377434e-03 4.0791657e-02 3.9713643e-03\n",
      "  6.5806619e-04 5.3505355e-04 1.5243875e-02 9.3455799e-03 2.8657492e-03\n",
      "  6.6606596e-02 3.7220389e-02 7.7060605e-03 5.3258534e-03 2.0850562e-03]]\n",
      "[[9.6233428e-01 2.0096281e-01 2.3323011e-01 9.1673449e-02 4.0219955e-02\n",
      "  2.6912764e-03 5.6986183e-02 4.0712830e-02 3.5761627e-03 3.3900749e-02\n",
      "  5.9443903e-03 1.3436823e-02 1.3769838e-01 3.4276400e-02 1.1441193e-02\n",
      "  2.4423603e-02 1.2502227e-02 5.3462781e-02 9.4033154e-03 2.4498127e-02\n",
      "  7.1465254e-02 2.7522925e-02 7.1233228e-02 1.0221729e-02 2.2217367e-02\n",
      "  8.7305316e-04 3.8653626e-03 2.8155506e-02 8.5726157e-03 4.6076752e-02\n",
      "  3.9658930e-02 7.3386863e-04 8.7894471e-03 9.9954829e-03 3.9879009e-03\n",
      "  6.9194594e-03 1.6460378e-03 1.8839516e-03 3.0991154e-02 3.7637451e-03\n",
      "  7.3796988e-04 4.9279403e-04 1.8200329e-02 1.0167997e-02 3.1312034e-03\n",
      "  4.0111348e-02 3.8744453e-02 1.0793096e-02 5.7690297e-03 2.1932651e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1, 119,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.093656234\n",
      "Comprehensiveness for iteration:  1.0263684\n",
      "Sufficency for iteration:  0.091250114\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0263684\n",
      "Comprehensiveness q1 (25% percentile):  1.0263683795928955\n",
      "Comprehensiveness q3 (75% percentile):  1.0263683795928955\n",
      "\n",
      "\n",
      "Sufficency Median:  0.091250114\n",
      "Sufficency q1 (25% percentile):  0.09125011414289474\n",
      "Sufficency q3 (75% percentile):  0.09125011414289474\n",
      "\n",
      "9\n",
      "input type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628e194190a04b0b82148bbfd47f3892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 2it [00:44, 44.80s/it]               \n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[296]\n",
      "indices_array: [[  0]\n",
      " [296]]\n",
      "instance other removed typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "instance other removed two typed:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "rational removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "other removed type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "batch type:  <class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "Currently interpreting instance:  0\n",
      "Calculating Sufficiency\n",
      "{'input_ids': tensor([[  101,  2673,   131,   175,  1555,   131, 24928, 11955,  6385, 26206,\n",
      "          1183,  1155,  1200, 19310,   131,  1185,  1227,  1155,  1200, 19310,\n",
      "           120, 16798,  3850,  9535,   168,   168,   168,   119,  2705, 12522,\n",
      "           131, 16320,  1116,  1558, 13467,  1137, 19849,  7791,   131,   168,\n",
      "           168,   168,   118,  4841, 13335,  6617, 18965,  1348,   172, 23851,\n",
      "         12355,  4527,  1111,  1231, 25461,  1104,   172,  9014, 23033,  1197,\n",
      "          8241,  1988,  1607,  1104,  1675,  6946,   131,   168,   168,   168,\n",
      "          1110,   170,   168,   168,   168,  2130,  1114,   177,  1775, 21831,\n",
      "          1126,  8816,  6834,  1306, 13500,  2624,  1107,   168,   168,   168,\n",
      "          1150,  8218,  1121,   184,  2737,  1114,  1286,   172,  9014, 23033,\n",
      "          1197,   177,  1183,  5674,  2883, 13730,  6995,  1111, 10311,  8241,\n",
      "          1988,   119,  5351,  3756,  1115,  1210,  2277,  2403,  1131,  1408,\n",
      "          1515, 16320,  1116,   117,  1134,  1110, 22832,  1111,  1123,   119,\n",
      "          1131,  4856,  1103, 16320,  1116,  1106,  1129,  4265,  1105, 10820,\n",
      "          1114,   189, 12415,  2728,  1233,   117,  1133,  1120,  1103,  4997,\n",
      "          1108,  1126,   168,   168,   168,   119,  1131,  1145,  3756,  1515,\n",
      "          7262,  3179,   117,  1134,  1145,  1408,  1164,  1210,  2277,  2403,\n",
      "           119,  1131,  4856,  1123,  3179,  1112,   107,   188, 21365, 27910,\n",
      "          1334,  1106,  1334,   119,   107,  1131, 26360,  1251,  4152,  2607,\n",
      "           117, 22882,   117, 26979,  1158,   117,  6406,   117,  1137,  1937,\n",
      "          4006,  7262,   119,  1131,  1486,  1123,  2552,  3995,  1142,  2106,\n",
      "          1111,  9285,  3143,   117,  1150,  2752,  1123,  1106,  1103,  5048,\n",
      "          1111, 10540,  1104,  1292,  8006,   119,   184,  2737,   172,  1204,\n",
      "          2799,  1126,  1298,  1104,   177,  1183,  5674,  2883, 13730,  1107,\n",
      "          1103,  1286,   172,  9014, 14545,  1818,   117,  6995,  1111, 10311,\n",
      "          8241,  1988,   119,  1131,  1108,  2886,  3175,  1106,   168,   168,\n",
      "           168,   119,  1104,  3805,   117,  5351,  3756,  1123,  1126,  8816,\n",
      "          6834,  1306, 13500,  1110,  1136,   182,  2047, 12173,   119,  1763,\n",
      "          2657,  1607,   131,   118,   168,   168,   168,   118,   177, 24312,\n",
      "         23826,  1988,   118,   188,   120,   185,     1,  8816,  6834,  1306,\n",
      "         13500,  2624,   168,   168,   168,  1120,   168,   168,   168,  1118,\n",
      "           173,  1197,   119,   168,   168,   168,  1934,  1607,   131,   168,\n",
      "           168,   168,  1266,  1607,   131,  1185,  1227,  1607,  1104,  6625,\n",
      "           117,  4182,   117,  1126,  8816,  6834,  1306,   119,  2952, 12211,\n",
      "           131,  1113, 10296,   131,   184,   131,   189,   131,  5311,   119,\n",
      "           130,   171,  1643,   131,  7029,   120,  5073,   177,  1197,   131,\n",
      "          3324,   187,  1479,   184,  1477, 28027,  1116,  5103,   110,   187,\n",
      "          1161,   176,  1424,   131,   192,  1181,   120,   192,  1179,   117,\n",
      "          6062,   117,  9468,  1181,   119,  1119,  3452,   131,  7035,   131,\n",
      "           181,   168,   168,   168,   117,   187,   168,   168,   168,   174,\n",
      "         17112,  1554,  2455,   131, 28117,  8661,  1513,   119,  4252,  7877,\n",
      "          1306,   131,  3258,  1105,  1218,   118,  1679, 21089,   119, 24928,\n",
      "         11955,   131,  4910,  2781,   131,  8264,  1105, 10427,   117, 14561,\n",
      "          1114, 12211,   117,  2999,  6975,   119, 10592,   131,  7779,  1106,\n",
      "          1825,   117,  1282,   117,  1105,  2236,   119,  1846,   131,  4055,\n",
      "         21785,  1114,  1363,  3254,  1643, 17121,  1105, 27753,   119, 10505,\n",
      "          9964,   119,  1185,   173,  6834,  9349,  8167,  1465,  1137, 18311,\n",
      "         20695,  5053,  1665, 11122,   119,   172, 23851,  1348, 10846,   131,\n",
      "           178,   131,  1136,  7289, 25550,   131,  1286, 11602,   126,   118,\n",
      "           125,  6262,   117,  1268,   125,   118,   124,  6262,   117,  1241,\n",
      "          7808, 26844,  1106,  1609,   119, 25550,  1182,   117,   178,  1964,\n",
      "           117,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "[[9.7523457e-01 2.6482803e-01 3.5413271e-01 7.6723360e-02 2.4308892e-02\n",
      "  3.2936258e-03 5.7075799e-02 2.4914477e-02 1.9288622e-03 2.6551167e-02\n",
      "  4.7633965e-03 1.1041304e-02 1.1386706e-01 2.9679459e-02 1.7954377e-02\n",
      "  4.1306630e-02 6.1226189e-03 1.8976394e-02 9.9933688e-03 1.5936045e-02\n",
      "  2.6609734e-02 1.6095759e-02 6.9927931e-02 6.5171593e-03 1.1171692e-02\n",
      "  3.1230247e-04 3.7748578e-03 2.2325227e-02 4.9180067e-03 3.3961389e-02\n",
      "  2.6721314e-02 6.5343146e-04 8.7660141e-03 5.3358134e-03 2.8087946e-03\n",
      "  4.9362257e-03 1.7050804e-03 1.8595135e-03 2.7950274e-02 4.5303837e-03\n",
      "  5.4847007e-04 3.8562459e-04 1.3455395e-02 9.0571819e-03 2.3090348e-03\n",
      "  5.1485427e-02 3.3396602e-02 6.3116038e-03 4.0243161e-03 1.5711325e-03]]\n",
      "[[9.66032147e-01 2.26232335e-01 2.37242058e-01 6.43108413e-02\n",
      "  2.85450425e-02 4.61592339e-03 4.26229462e-02 1.91966873e-02\n",
      "  2.24827277e-03 2.80880947e-02 4.64821048e-03 1.08713340e-02\n",
      "  1.00790493e-01 2.58875545e-02 8.54728371e-03 2.53371932e-02\n",
      "  6.17520465e-03 2.51829512e-02 8.59383401e-03 1.88439526e-02\n",
      "  3.81117836e-02 1.81952622e-02 4.92669307e-02 8.02457053e-03\n",
      "  1.37562156e-02 7.00272853e-04 3.29443207e-03 1.68101862e-02\n",
      "  5.98275987e-03 2.82573495e-02 2.18808800e-02 6.89642446e-04\n",
      "  6.10870356e-03 4.51047765e-03 1.93534116e-03 5.40347258e-03\n",
      "  2.48553418e-03 1.69017387e-03 3.40553559e-02 3.56240757e-03\n",
      "  6.57973695e-04 3.67793051e-04 1.53060518e-02 1.02839805e-02\n",
      "  2.71634012e-03 3.18740234e-02 2.27642711e-02 6.14515040e-03\n",
      "  3.48003767e-03 1.10051397e-03]]\n",
      "[[9.7523457e-01 2.6482803e-01 3.5413271e-01 7.6723360e-02 2.4308892e-02\n",
      "  3.2936258e-03 5.7075799e-02 2.4914477e-02 1.9288622e-03 2.6551167e-02\n",
      "  4.7633965e-03 1.1041304e-02 1.1386706e-01 2.9679459e-02 1.7954377e-02\n",
      "  4.1306630e-02 6.1226189e-03 1.8976394e-02 9.9933688e-03 1.5936045e-02\n",
      "  2.6609734e-02 1.6095759e-02 6.9927931e-02 6.5171593e-03 1.1171692e-02\n",
      "  3.1230247e-04 3.7748578e-03 2.2325227e-02 4.9180067e-03 3.3961389e-02\n",
      "  2.6721314e-02 6.5343146e-04 8.7660141e-03 5.3358134e-03 2.8087946e-03\n",
      "  4.9362257e-03 1.7050804e-03 1.8595135e-03 2.7950274e-02 4.5303837e-03\n",
      "  5.4847007e-04 3.8562459e-04 1.3455395e-02 9.0571819e-03 2.3090348e-03\n",
      "  5.1485427e-02 3.3396602e-02 6.3116038e-03 4.0243161e-03 1.5711325e-03]]\n",
      "Calculating Comprehensiveness\n",
      "{'input_ids': tensor([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1, 1126,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
      "instances batch size:  torch.Size([1, 512])\n",
      "\n",
      "-- Metrics -------------------------------------------------------------\n",
      "\n",
      "\n",
      "Faithfulness for iteration:  0.13393429\n",
      "Comprehensiveness for iteration:  1.0140507\n",
      "Sufficency for iteration:  0.13207848\n",
      "\n",
      "\n",
      "Comprehensiveness Median:  1.0140507\n",
      "Comprehensiveness q1 (25% percentile):  1.0140507221221924\n",
      "Comprehensiveness q3 (75% percentile):  1.0140507221221924\n",
      "\n",
      "\n",
      "Sufficency Median:  0.13207848\n",
      "Sufficency q1 (25% percentile):  0.13207848370075226\n",
      "Sufficency q3 (75% percentile):  0.13207848370075226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  For our evaluation, we fix for 10 examples and choose k = 5, 10, 15.\n",
    "start_index = 0\n",
    "N = 10\n",
    "B = 1\n",
    "masker = shap.maskers.Text(pipeline.tokenizer)\n",
    "explainer = shap.Explainer(pipeline, masker)\n",
    "input_data =  dataset['test']['text']\n",
    "\n",
    "k = 5\n",
    "_, overall_faith_5, avg_faith_5 = get_faith_shap(input_data, start_index, N, B, k)\n",
    "k = 10\n",
    "_, overall_faith_10, avg_faith_10 = get_faith_shap(input_data, start_index, N, B, k)\n",
    "k = 15\n",
    "_, overall_faith_15, avg_faith_15 = get_faith_shap(input_data, start_index, N, B, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 5:\n",
      "overall_faith: [0.12282419, 0.117213875, 0.064900264, 0.11008728, 0.10610219, 0.21381745, 0.103904635, 0.083802536, 0.09123538, 0.12878683]\n",
      "avg faith: 0.11426747\n",
      "For k = 10:\n",
      "overall_faith: [0.09830999, 0.10666947, 0.06897583, 0.14220554, 0.12074634, 0.122300334, 0.0930727, 0.47959316, 0.056425303, 0.118119985]\n",
      "avg faith: 0.14064187\n",
      "For k = 15:\n",
      "overall_faith: [0.48845753, 0.0691035, 0.18289092, 0.088048644, 0.11520019, 0.11343779, 0.057432324, 0.07895278, 0.093656234, 0.13393429]\n",
      "avg faith: 0.1421114\n"
     ]
    }
   ],
   "source": [
    "print('For k = 5:')\n",
    "print('overall_faith:', overall_faith_5)\n",
    "print('avg faith:', avg_faith_5)\n",
    "print('For k = 10:')\n",
    "print('overall_faith:', overall_faith_10)\n",
    "print('avg faith:', avg_faith_10)\n",
    "print('For k = 15:')\n",
    "print('overall_faith:', overall_faith_15)\n",
    "print('avg faith:', avg_faith_15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
