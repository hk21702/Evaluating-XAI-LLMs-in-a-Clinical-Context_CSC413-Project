{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/u11/c0/00/ammcourt/miniconda3/envs/csc413/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    OPTForSequenceClassification,\n",
    "    Pipeline,\n",
    ")\n",
    "\n",
    "import wandb\n",
    "\n",
    "MODEL = \"facebook/opt-350m\"\n",
    "MAX_POSITION_EMBEDDINGS = 2048\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = \"OPT-350m-mimic-full\"\n",
    "VAL_DATASET_PATH = \"data/val_9.csv\"\n",
    "CODE_PATH = \"data/icd9_codes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True, device=device)\n",
    "\n",
    "code_labels = pd.read_csv(\"data/icd9_codes.csv\")\n",
    "dataset = load_dataset(\"csv\", data_files=VAL_DATASET_PATH)\n",
    "\n",
    "# Create class dictionaries\n",
    "classes = [class_ for class_ in code_labels[\"icd_code\"] if class_]\n",
    "class2id = {class_: id for id, class_ in enumerate(classes)}\n",
    "id2class = {id: class_ for class_, id in class2id.items()}\n",
    "\n",
    "\n",
    "def multi_labels_to_ids(labels: list[str]) -> list[float]:\n",
    "    ids = [0.0] * len(class2id)  # BCELoss requires float as target type\n",
    "    for label in labels:\n",
    "        ids[class2id[label]] = 1.0\n",
    "    return ids\n",
    "\n",
    "\n",
    "def preprocess_function(example):\n",
    "    result = tokenizer(\n",
    "        example[\"text\"], truncation=True, max_length=MAX_POSITION_EMBEDDINGS\n",
    "    )\n",
    "    result[\"labels\"] = [multi_labels_to_ids(eval(label)) for label in example[\"labels\"]]\n",
    "    return result\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    preprocess_function, load_from_cache_file=True, batched=True, num_proc=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttentionLayerBetterTransformer(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1024, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=512, out_features=51, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config, unused_kwargs = AutoConfig.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(classes),\n",
    "    id2label=id2class,\n",
    "    label2id=class2id,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    return_unused_kwargs=True,\n",
    ")\n",
    "\n",
    "if unused_kwargs:\n",
    "    print(f\"Unused kwargs: {unused_kwargs}\")\n",
    "\n",
    "model = OPTForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    config=config,\n",
    ").to(device)\n",
    "\n",
    "model.load_adapter(CHECKPOINT_DIR)\n",
    "model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Sex:   M\\n \\nService: SURGERY\\n \\nAllergies: \\nGrass ___, Standard / Lactose\\n \\n ___.\\n \\nChief Complaint:\\nright popliteal aneurysm\\n \\nMajor Surgical or Invasive Procedure:\\n___: popliteal artery stent graft\\n\\n \\nHistory of Present Illness:\\nMr. ___ has a fairly focal aneurysm in the\\nmid right popliteal artery and is mostly full of thrombus and\\nmeasures 3.1 cm.  It is patent and does have palpable pedal\\npulse distally.  He has need of upcoming ankle surgery as well.\\nHe has a past medical history notable for breast cancer status\\npost mastectomy and chemotherapy/radiation therapy with duodenal\\nulcer, pseudogout, depression, hypothyroidism, microvascular\\ncerebrovascular disease, hyperlipidemia, and COPD.  He had vein\\nmapping performed today which shows the lesser saphenous veins\\nto be small and noncompressible bilaterally.  He has the\\nthrombosis of the right greater saphenous at the level of the\\nknee.  The left greater saphenous is adequate as are both\\nbasilic and cephalic veins.  It was decided that he would best \\nbe served by a stent graft. He was set up to have this done \\nelectively\\n \\nPast Medical History:\\nDepression\\nPseudogout\\nThyroid nodule\\nHx Duodenal ulcer ___ dx at OSH; ? secondary to ASA per pt.\\nHypothyroidism\\nCNS microvascular disease\\nHypercholesterolemia\\nNon-ulcer dyspepsia\\nAnemia\\nX-rays showing COPD although no smoking hx per pt.\\nBreast Cancer - T2, N1 ___ nodes), M0, grade III, double \\nhormone\\nreceptor positive and HER-2/neu negative infiltrating ductal\\ncarcinoma.  Lymphovascular invasion was also present.  He was\\ntreated with a total mastectomy, adjuvant chemotherapy with four\\ncycles of Taxotere and Cytoxan, followed by postmastectomy\\nradiation.  Currently on anastrozole.\\n\\n \\nPSH: Umbilical hernia repair ___, Right mastoid operation as \\na teenager, total mastectomy\\n\\n \\nSocial History:\\n___\\nFamily History:\\nnon contributory\\n \\nPhysical Exam:\\nvss afebrile\\n\\nGen - Elderly appearing male in nad, alert and oriented x 3\\nCV - RRR\\nLungs - CTA bilat\\nAbd - soft no m/t/o\\nExtremities - R ankle weakness (baseline). Full ROM of bilat ___. \\nRLE edema 1+. No LLE edema. R groin puncture c/d/i\\nPulses - femoral/dp/pt palpable bilat\\n \\nPertinent Results:\\n___ 09:20PM BLOOD WBC-4.4 RBC-3.96* Hgb-11.6* Hct-34.4* \\nMCV-87 MCH-29.4 MCHC-33.8 RDW-13.0 Plt ___\\n___ 07:30AM BLOOD WBC-5.5 RBC-3.99* Hgb-11.7* Hct-34.8* \\nMCV-87 MCH-29.4 MCHC-33.7 RDW-13.1 Plt ___\\n___ 09:20PM BLOOD Glucose-88 UreaN-12 Creat-0.9 Na-142 \\nK-4.3 Cl-105 HCO3-26 AnGap-15\\n___ 07:30AM BLOOD Glucose-144* UreaN-14 Creat-1.0 Na-139 \\nK-4.5 Cl-103 HCO3-30 AnGap-11\\n___ 09:20PM BLOOD Calcium-8.7 Phos-2.9 Mg-1.9\\n___ 07:30AM BLOOD Calcium-8.9 Phos-3.7 Mg-2.5\\n \\nBrief Hospital Course:\\nMr. ___ was admitted, preop'd, consented and taken for right \\npopliteal stent graft. Just prior to the operation he had an \\nepisode of sinus tachycardia, but quickly returned to his \\nbaseline which is sinus bradycardia. He tolerated the procedure \\nwell and was transfered to the PACU where he remained \\nhemodynamicaly stable. He did have another episode of sinus \\ntachycardia in the PACU and received several doses of IV \\nmetoprolol.  He rapidly converted to sinus bradycardia with \\nrates in the ___.  His blood pressure was stable throughout \\nthese episodes and he was completely asymptomatic. He was \\ntransfered to the VICU for monitoring overnight. He remained in \\nsinus rhythm with heart rate stable in the ___. Review of \\nrecords and discussion with his PCP revealed that he has had \\nother episodes of sinus tach in the setting of procedures and \\noutpatient work up did not reveal anything significant. His \\nbaseline HR is sinus bradycardia in the high ___.  We had our \\nelectrophysiology team here see him and they felt there was no \\nacute issue. They did recommend he follow up with his PCP or \\ncardiologist and have an outpatient echo.  Mr. ___ was \\nfeeling well on POD 1. His lab values were stable, he tolerated \\na regular diet and voided without difficulty.  He did walk with \\nhis cane but was a bit unsteady. ___ evaluated him and felt he \\nwould benefit from a walker and home ___. He was deemed stable \\nfor d/c home with family with a walker and a ___ and home ___. He \\nwill follow up with vascular, and his pcp in the near future. \\n \\nMedications on Admission:\\n anastrozole 1 mg qd;  \\n  colchicine 0.6 mg qd' DIAZEPAM 5MG prn;  levothyroxine 75 mcg \\nqd;  pravastatin 80 mg qd; ranitidine HCl 300 mg bid;        \\n  aspirin 325 qd\\n \\nDischarge Medications:\\n1. oxycodone-acetaminophen ___ mg Tablet Sig: One (1) Tablet \\nPO Q6H (every 6 hours) as needed for pain.\\nDisp:*10 Tablet(s)* Refills:*0*\\n2. docusate sodium 100 mg Capsule Sig: One (1) Capsule PO BID (2 \\ntimes a day): while on narcotics.  \\n3. levothyroxine 75 mcg Tablet Sig: One (1) Tablet PO DAILY \\n(Daily).  \\n4. pravastatin 80 mg Tablet Sig: One (1) Tablet PO once a day.  \\n5. anastrozole 1 mg Tablet Sig: One (1) Tablet PO once a day.  \\n6. colchicine 0.6 mg Tablet Sig: One (1) Tablet PO once a day.  \\n7. diazepam 5 mg Tablet Sig: One (1) Tablet PO at bedtime as \\nneeded for insomnia.  \\n8. ranitidine HCl 150 mg Tablet Sig: Two (2) Tablet PO BID (2 \\ntimes a day).  \\n9. aspirin 325 mg Tablet Sig: One (1) Tablet PO DAILY (Daily).  \\n10. clopidogrel 75 mg Tablet Sig: One (1) Tablet PO DAILY \\n(Daily) for 1 months: for 1 month then stop.\\nDisp:*30 Tablet(s)* Refills:*0*\\n\\n \\nDischarge Disposition:\\nHome With Service\\n \\nFacility:\\n___\\n \\nDischarge Diagnosis:\\nR popiteal artery anuerysm\\n\\n \\nDischarge Condition:\\nMental Status: Clear and coherent.\\nLevel of Consciousness: Alert and interactive.\\nActivity Status: Ambulatory - requires assistance or aid (walker \\nor cane).\\n\\n \\nDischarge Instructions:\\nDivision of Vascular and Endovascular Surgery\\nLower Extremity Angioplasty/Stent Discharge Instructions\\n\\nMedications:\\n\\x95Take Aspirin 325mg (enteric coated) once daily \\n\\x95If instructed, take Plavix (Clopidogrel) 75mg once daily\\n\\x95Continue all other medications you were taking before surgery, \\nunless otherwise directed\\n\\x95You make take Tylenol or prescribed pain medications for any \\npost procedure pain or discomfort\\n\\nWhat to expect when you go home:\\nIt is normal to have slight swelling of the legs:\\n\\x95Elevate your leg above the level of your heart (use ___ \\npillows or a recliner) every ___ hours throughout the day and at \\nnight\\n\\x95Avoid prolonged periods of standing or sitting without your \\nlegs elevated\\n\\x95It is normal to feel tired and have a decreased appetite, your \\nappetite will return with time \\n\\x95Drink plenty of fluids and eat small frequent meals\\n\\x95It is important to eat nutritious food options (high fiber, \\nlean meats, vegetables/fruits, low fat, low cholesterol) to \\nmaintain your strength and assist in wound healing\\n\\x95To avoid constipation: eat a high fiber diet and use stool \\nsoftener while taking pain medication\\n\\nWhat activities you can and cannot do:\\n\\x95When you go home, you may walk and go up and down stairs\\n\\x95You may shower (let the soapy water run over groin incision, \\nrinse and pat dry)\\n\\x95Your incision may be left uncovered, unless you have small \\namounts of drainage from the wound, then place a dry dressing or \\nband aid over the area that is draining, as needed\\n\\x95No heavy lifting, pushing or pulling (greater than 5 lbs) for \\n1 week (to allow groin puncture to heal)\\n\\x95After 1 week, you may resume sexual activity\\n\\x95After 1 week, gradually increase your activities and distance \\nwalked as you can tolerate\\n\\x95No driving until you are no longer taking pain medications\\n\\x95Call and schedule an appointment to be seen in ___ weeks for \\npost procedure check and ultrasound \\n\\nWhat to report to office:\\n\\x95Numbness, coldness or pain in lower extremities \\n\\x95Temperature greater than 101.5F for 24 hours\\n\\x95New or increased drainage from incision or white, yellow or \\ngreen drainage from incisions\\n\\x95Bleeding from groin puncture site\\n\\nSUDDEN, SEVERE BLEEDING OR SWELLING (Groin puncture site)\\n\\x95Lie down, keep leg straight and have someone apply firm \\npressure to area for 10 minutes. If bleeding stops, call \\nvascular office ___. If bleeding does not stop, call \\n___ for transfer to closest Emergency Room.\\n\\nYou need to follow up with your cardiologist and primary care \\ndoctor regarding your baseline bradycardia.  You should have \\nyour thyroid function followed closely.  \\n \\nFollowup Instructions:\\n___\", 'labels': \"['d-496', 'd-2720']\"}\n"
     ]
    }
   ],
   "source": [
    "untokenized_dataset = load_dataset(\"csv\", data_files=VAL_DATASET_PATH)\n",
    "\n",
    "print(untokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    untokenized_dataset[\"train\"][0][\"text\"],\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=MAX_POSITION_EMBEDDINGS,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT_ICD9_Pipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        return self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=MAX_POSITION_EMBEDDINGS,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        outputs = self.model(**model_inputs)\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        # logits = model_outputs.logits[0].numpy()\n",
    "        #print(logits)\n",
    "        probs = model_outputs[\"logits\"].sigmoid()\n",
    "\n",
    "        output = []\n",
    "        for i, prob in enumerate(probs[0]):\n",
    "            label = self.model.config.id2label[i]\n",
    "            score = prob\n",
    "            output.append({\"label\": label, \"score\": score})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = OPT_ICD9_Pipeline(model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(untokenized_dataset[\"train\"][2][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = shap.maskers.Text(pipeline.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = shap.sample(untokenized_dataset[\"train\"][\"text\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(pipeline, masker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untokenized_dataset[\"train\"][:2][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(untokenized_dataset[\"train\"][:5][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0, :, \"d-2749\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = shap.plots.text(shap_values[0, :, \"d-2749\"], display = False)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shap_values)\n",
    "\n",
    "print(explainer.feature_names)\n",
    "print(len(shap_values.values[1]))\n",
    "# print(shap_values[0, :, \"d-2749\"].values)\n",
    "print(len(shap_values[0, :, \"d-2749\"].values))\n",
    "# print(len(shap_values.values[0]))\n",
    "# print(len(shap_values.base_values[0]))\n",
    "# print(len(shap_values.data[0]))\n",
    "\n",
    "# print(shap_values.values[0])\n",
    "# print(shap_values.base_values[0])\n",
    "# print(shap_values.data[0])\n",
    "\n",
    "max_indices = []\n",
    "for val in shap_values.values[0]:\n",
    "    print(val)\n",
    "    inde = np.argmax(val)\n",
    "    if inde not in max_indices:\n",
    "        max_indices.append(inde)\n",
    "    \n",
    "print(max_indices)\n",
    "\n",
    "# feature_names = untokenized_dataset[\"train\"].columns\n",
    "# rf_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "# vals = np.abs(rf_resultX.values).mean(0)\n",
    "\n",
    "# shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "#                                   columns=['col_name','feature_importance_vals'])\n",
    "# shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "#                                ascending=False, inplace=True)\n",
    "# shap_importance.head()\n",
    "\n",
    "\n",
    "# values, clustering = unpack_shap_explanation_contents(v)\n",
    "#             tokens, values, group_sizes = process_shap_values(v.data, values, grouping_threshold, separator, clustering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shap pipeline works in the following order:\n",
    "- Generate the indices array (note this array corresponds to tokens, not strings)\n",
    "- Tokenize the input dataset\n",
    "- Pass the tokenized input dataset to the masking functions along with the indices\n",
    "- The pass all tokenized and masked tokenized datasets to the faithfulness calcuation\n",
    "\n",
    "This requires a prediction function that expects a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_arrays_shap(inputs, pred_func, model, tokenizer, top_k = 5):\n",
    "    \"\"\" Function to create the arrays corresponding to the shap \n",
    "    \n",
    "    The output is in the format [[input_index_0, input_index_0, ... input_index_n, input_index_n], \n",
    "    [rationale_token_index_0 (for input 0), rationale_token_index_1 (for input 0), ... rationale_token_index_k-1 (for input n), rationale_token_index_k (for input n)]]. \n",
    "    This is used as an indexing array for masking.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # get the shap values over the inputs\n",
    "    # shap_values = explainer(inputs, batch_size=5)\n",
    "    \n",
    "    # get the mode inferences for the inputs\n",
    "    inferences = pred_func(inputs, model, tokenizer)\n",
    "    indices_array = None\n",
    "    # get the longest \n",
    "    \n",
    "    for i, val in enumerate(shap_values):\n",
    "        # get the choosen labels\n",
    "        print(\"Inferences: \", inferences)\n",
    "        choosen_labels = np.where(inferences[i] > 0.5)\n",
    "        choosen_labels = np.unique(choosen_labels)\n",
    "        \n",
    "        # convert the indices to labels\n",
    "        choosen_labels = np.array(choosen_labels).astype(int)\n",
    "        print(\"Choosen label: \", choosen_labels)\n",
    "        choosen_labels = [id2class[label] for label in choosen_labels]\n",
    "        print(id2class)\n",
    "        print(choosen_labels)\n",
    "        \n",
    "        # for each shap value, index in via it's choosen labels\n",
    "        total_top_k_indices = np.array([])\n",
    "        top_val = min(top_k, len(choosen_labels))\n",
    "        print(top_val)\n",
    "        print(choosen_labels)\n",
    "        \n",
    "        \n",
    "        for label in choosen_labels:\n",
    "            # get the top k shap value indices\n",
    "            print(label)\n",
    "            top_k_indices = np.argsort(shap_values[i, :, label].values)[-top_val:]\n",
    "            print(top_k_indices)\n",
    "            total_top_k_indices = np.append(total_top_k_indices, top_k_indices)\n",
    "        \n",
    "        # sort the indices array to be in ascending order\n",
    "        total_top_k_indices = np.sort(total_top_k_indices)\n",
    "        # remove duplicates\n",
    "        total_top_k_indices = np.unique(total_top_k_indices)\n",
    "        # this might be wrong, it seems like shap returns indices outside of the token range\n",
    "        # so I'm not sure if shap is using the same tokenization function as ours.\n",
    "        total_top_k_indices = total_top_k_indices[total_top_k_indices < 2048]\n",
    "        \n",
    "        # create a array of the same shape of total_top_k_indices and fill with value i\n",
    "        index_array = np.full(total_top_k_indices.shape, i)\n",
    "        \n",
    "        if i == 0:\n",
    "            indices_array = [index_array.tolist(), total_top_k_indices.tolist()]\n",
    "        else:\n",
    "            # append index array to indices array[0]\n",
    "            indices_array[0] = indices_array[0] + index_array.tolist()\n",
    "            # append total_top_k_indices to indices array[1]\n",
    "            indices_array[1] = indices_array[1] + total_top_k_indices.tolist()\n",
    "    \n",
    "    return np.array(indices_array).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_model_token(texts, model, tokenizer):\n",
    "    # print(len(texts))\n",
    "    tk = tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS).to(device)\n",
    "    print(type(tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS)))\n",
    "    print(\"token_att: \", dir(tk))\n",
    "    outputs = model(**tk)\n",
    "    tensor_logits = outputs[0]\n",
    "    probas = tensor_logits.sigmoid().detach().cpu().numpy()\n",
    "    return probas\n",
    "\n",
    "def predictor_model_no_token(texts, model, tokenizer):\n",
    "    # print(len(texts))\n",
    "    # tk = tokenizer(texts, return_tensors=\"pt\",truncation=True, padding=True, max_length=MAX_POSITION_EMBEDDINGS).to(device)\n",
    "    # tokenization is removed but still need to set texts to device\n",
    "    # i'm not sure why this is a list and don't have time to debug\n",
    "    print(\"Texts_type:\", type(texts))\n",
    "    print(\"Texts_dir:\",  dir(texts))\n",
    "    texts.to(device)\n",
    "    outputs = model(**texts)\n",
    "    tensor_logits = outputs[0]\n",
    "    probas = tensor_logits.sigmoid().detach().cpu().numpy()\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faithfulness\n",
    "# this reimports the library for easy testing in the notebook\n",
    "import importlib\n",
    "importlib.reload(faithfulness)\n",
    "\n",
    "MAX_LEN=2048\n",
    "   \n",
    "# tokenize the test dataset\n",
    "test_data = untokenized_dataset[\"train\"][:5][\"text\"]\n",
    "\n",
    "inputs = tokenizer(test_data, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='pt')\n",
    "print(inputs['input_ids'][0][2:30])\n",
    "print(\"input type: \", type(inputs))\n",
    "\n",
    "indices_array = get_index_arrays_shap(test_data, predictor_model_token, model, tokenizer)\n",
    "print(indices_array)\n",
    "\n",
    "inputs_rationale_removed = faithfulness.remove_rationale_words(inputs, indices_array, join=False, tokenized=True)\n",
    "inputs_other_removed = faithfulness.remove_other_words(inputs, indices_array, join=False, tokenized=True)\n",
    "\n",
    "print(\"rational removed type: \", type(inputs_rationale_removed))\n",
    "print(\"other removed type: \", type(inputs_other_removed))\n",
    "\n",
    "ind, faith = faithfulness.calculate_faithfulness(inputs, [inputs_rationale_removed], [inputs_other_removed ], model, tokenizer, predictor_model_no_token, tokenized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
